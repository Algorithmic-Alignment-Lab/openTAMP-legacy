{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(15),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7cb36750>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7cb360d0>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd7dc47150>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd93224110>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbd7ce53550>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0., -3.,  2.,  0.,  0.,  0.,  0.,  0., -3.,  2.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd93224f90>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 1.0,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0.,  0.,  0., -3.,  2.])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 1000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 5000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [20],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd7cb36190>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 10,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd93224f90>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 1.0,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0.,  0.,  0., -3.,  2.])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 1000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 5000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [20],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd7cb36190>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 10,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [20],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 1000.0,
 'plan_f': <function <lambda> at 0x7fbd7ccbac80>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 5000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[ 0.          0.          0.         -3.          2.        ]
 [-0.18561588  0.08823377 -0.01158445 -3.          2.        ]
 [-0.31165677  0.16047899 -0.00336708 -3.          2.        ]
 [-0.42330068  0.22449119  0.00390903 -3.          2.        ]
 [-0.53384548  0.2878831   0.01111227 -3.          2.        ]
 [-0.63671249  0.34687573  0.01781462 -3.          2.        ]
 [-0.73272532  0.40193766  0.02407036 -3.          2.        ]
 [-0.82286924  0.45363414  0.02994368 -3.          2.        ]
 [-0.90735382  0.50208503  0.03544827 -3.          2.        ]
 [-0.98651797  0.54748464  0.04060622 -3.          2.        ]
 [-1.06071436  0.59003556  0.0454405  -3.          2.        ]
 [-1.13025284  0.62991488  0.04997127 -3.          2.        ]
 [-1.1954242   0.66728997  0.05421751 -3.          2.        ]
 [-1.25650334  0.70231795  0.05819712 -3.          2.        ]
 [-1.31374717  0.73514664  0.06192685 -3.          2.        ]
 [-1.36739647  0.76591396  0.06542237 -3.          2.        ]
 [-1.41767728  0.79474938  0.0686984  -3.          2.        ]
 [-1.46480083  0.82177389  0.07176874 -3.          2.        ]
 [-1.50896502  0.84710181  0.07464629 -3.          2.        ]
 [-1.55035639  0.870839    0.07734311 -3.          2.        ]]

STEP 1:
[[-1.55035639  0.870839    0.07734311 -3.          2.        ]
 [-1.60760021  0.90367234  0.08107222 -3.          2.        ]
 [-1.64688706  0.92620039  0.08363231 -3.          2.        ]
 [-1.68038857  0.94541144  0.08581528 -3.          2.        ]
 [-1.71045101  0.96265113  0.08777414 -3.          2.        ]
 [-1.73924625  0.97916508  0.08965024 -3.          2.        ]
 [-1.76621854  0.99463344  0.09140762 -3.          2.        ]
 [-1.79144144  1.00909841  0.09305102 -3.          2.        ]
 [-1.81509447  1.02266324  0.09459213 -3.          2.        ]
 [-1.83726466  1.0353775   0.09603662 -3.          2.        ]
 [-1.85804081  1.04729247  0.09739031 -3.          2.        ]
 [-1.87751269  1.05845928  0.098659   -3.          2.        ]
 [-1.89576197  1.06892502  0.09984802 -3.          2.        ]
 [-1.91286552  1.07873368  0.10096239 -3.          2.        ]
 [-1.928895    1.08792627  0.1020068  -3.          2.        ]
 [-1.94391775  1.09654176  0.10298562 -3.          2.        ]
 [-1.95799708  1.10461617  0.10390297 -3.          2.        ]
 [-1.9711926   1.11218345  0.1047627  -3.          2.        ]
 [-1.98355949  1.11927581  0.10556848 -3.          2.        ]
 [-1.99514985  1.1259228   0.10632364 -3.          2.        ]]

STEP 2:
[[-1.99514985  1.1259228   0.10632364 -3.          2.        ]
 [-2.01117921  1.1351167   0.10736787 -3.          2.        ]
 [-2.02218032  1.14142489  0.10808475 -3.          2.        ]
 [-2.03156137  1.14680433  0.10869601 -3.          2.        ]
 [-2.03997946  1.15163183  0.10924452 -3.          2.        ]
 [-2.04804277  1.15625632  0.10976986 -3.          2.        ]
 [-2.0555954   1.16058755  0.11026198 -3.          2.        ]
 [-2.06265831  1.16463804  0.11072216 -3.          2.        ]
 [-2.06928182  1.16843653  0.11115368 -3.          2.        ]
 [-2.07548976  1.17199683  0.11155821 -3.          2.        ]
 [-2.08130765  1.17533314  0.11193725 -3.          2.        ]
 [-2.08676028  1.17846012  0.11229251 -3.          2.        ]
 [-2.09187031  1.18139076  0.11262547 -3.          2.        ]
 [-2.09665966  1.18413734  0.11293752 -3.          2.        ]
 [-2.10114813  1.18671155  0.11322995 -3.          2.        ]
 [-2.10535502  1.18912387  0.11350406 -3.          2.        ]
 [-2.10929728  1.19138491  0.11376093 -3.          2.        ]
 [-2.11299229  1.19350386  0.11400165 -3.          2.        ]
 [-2.11645532  1.19548988  0.11422729 -3.          2.        ]
 [-2.11970067  1.19735122  0.11443876 -3.          2.        ]]

STEP 3:
[[-2.11970067  1.19735122  0.11443876 -3.          2.        ]
 [-2.12418914  1.19992566  0.11473117 -3.          2.        ]
 [-2.12726951  1.20169199  0.11493189 -3.          2.        ]
 [-2.1298964   1.20319819  0.11510304 -3.          2.        ]
 [-2.13225389  1.20455015  0.11525663 -3.          2.        ]
 [-2.13451171  1.205845    0.11540376 -3.          2.        ]
 [-2.13662672  1.20705795  0.11554155 -3.          2.        ]
 [-2.1386044   1.20819211  0.11567041 -3.          2.        ]
 [-2.14045906  1.2092557   0.11579125 -3.          2.        ]
 [-2.14219737  1.21025276  0.11590452 -3.          2.        ]
 [-2.14382648  1.21118689  0.11601067 -3.          2.        ]
 [-2.14535332  1.21206248  0.11611014 -3.          2.        ]
 [-2.14678454  1.21288311  0.11620336 -3.          2.        ]
 [-2.14812541  1.21365213  0.11629077 -3.          2.        ]
 [-2.14938211  1.21437299  0.11637265 -3.          2.        ]
 [-2.1505599   1.21504843  0.11644939 -3.          2.        ]
 [-2.15166378  1.21568155  0.11652131 -3.          2.        ]
 [-2.15269852  1.21627498  0.1165887  -3.          2.        ]
 [-2.1536684   1.21683097  0.11665192 -3.          2.        ]
 [-2.15457726  1.21735239  0.11671112 -3.          2.        ]]

STEP 4:
[[-2.15457726  1.21735239  0.11671112 -3.          2.        ]
 [-2.15583396  1.21807325  0.116793   -3.          2.        ]
 [-2.15669632  1.21856773  0.11684921 -3.          2.        ]
 [-2.15743184  1.21898949  0.11689713 -3.          2.        ]
 [-2.15809178  1.21936786  0.11694013 -3.          2.        ]
 [-2.15872431  1.21973038  0.11698133 -3.          2.        ]
 [-2.15931654  1.22007012  0.11701991 -3.          2.        ]
 [-2.15987015  1.22038782  0.11705599 -3.          2.        ]
 [-2.16038942  1.22068572  0.11708983 -3.          2.        ]
 [-2.16087627  1.22096479  0.11712155 -3.          2.        ]
 [-2.16133237  1.22122633  0.11715127 -3.          2.        ]
 [-2.16175961  1.22147143  0.11717912 -3.          2.        ]
 [-2.16216016  1.22170115  0.11720521 -3.          2.        ]
 [-2.16253567  1.22191644  0.11722966 -3.          2.        ]
 [-2.16288757  1.22211826  0.11725261 -3.          2.        ]
 [-2.16321754  1.22230744  0.1172741  -3.          2.        ]
 [-2.16352677  1.22248471  0.11729424 -3.          2.        ]
 [-2.16381645  1.222651    0.11731311 -3.          2.        ]
 [-2.16408801  1.22280681  0.11733083 -3.          2.        ]
 [-2.16434288  1.2229526   0.11734741 -3.          2.        ]]

