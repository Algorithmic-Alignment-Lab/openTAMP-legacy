{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(1),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbda60ba190>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbda60ba150>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbda608ed50>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbda60baed0>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbda6104ad0>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0. ,  0. ,  0. ,  0. ,  3.5,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,
        3.5,  0. ,  6. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbda6104d10>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 0.001,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0. ,  0. ,  0. ,  0. ,  3.5])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 1000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 1000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [20],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbdbfd43150>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 0.01,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbda6104d10>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 0.001,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0. ,  0. ,  0. ,  0. ,  3.5])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 1000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 1000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [20],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbdbfd43150>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 0.01,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [20],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 1000.0,
 'plan_f': <function <lambda> at 0x7fbda60acb18>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 1000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    3.50000000e+00]
 [  2.11627898e-03   1.74103931e-01  -1.77763347e-02   0.00000000e+00
    3.50000000e+00]
 [  2.11627898e-03   1.74103931e-01  -1.77763347e-02   0.00000000e+00
    3.50000000e+00]
 [  2.13380414e-03   2.02868074e-01  -1.44054350e-02   0.00000000e+00
    3.50000000e+00]
 [  2.16424884e-03   2.52836704e-01  -8.54955800e-03   0.00000000e+00
    3.50000000e+00]
 [  2.18473584e-03   2.86462367e-01  -4.60892823e-03   0.00000000e+00
    3.50000000e+00]
 [  2.20329920e-03   3.16930324e-01  -1.03835762e-03   0.00000000e+00
    3.50000000e+00]
 [  2.22113263e-03   3.46200287e-01   2.39181891e-03   0.00000000e+00
    3.50000000e+00]
 [  2.23695044e-03   3.72162193e-01   5.43432124e-03   0.00000000e+00
    3.50000000e+00]
 [  2.25121179e-03   3.95569324e-01   8.17742757e-03   0.00000000e+00
    3.50000000e+00]
 [  2.26418185e-03   4.16857123e-01   1.06721669e-02   0.00000000e+00
    3.50000000e+00]
 [  2.27590790e-03   4.36103106e-01   1.29276197e-02   0.00000000e+00
    3.50000000e+00]
 [  2.28651403e-03   4.53510880e-01   1.49676669e-02   0.00000000e+00
    3.50000000e+00]
 [  2.29611597e-03   4.69270468e-01   1.68145467e-02   0.00000000e+00
    3.50000000e+00]
 [  2.30480521e-03   4.83532310e-01   1.84859019e-02   0.00000000e+00
    3.50000000e+00]
 [  2.31266860e-03   4.96438384e-01   1.99983772e-02   0.00000000e+00
    3.50000000e+00]
 [  2.31978483e-03   5.08118451e-01   2.13671792e-02   0.00000000e+00
    3.50000000e+00]
 [  2.32622516e-03   5.18688738e-01   2.26059239e-02   0.00000000e+00
    3.50000000e+00]
 [  2.33205338e-03   5.28254747e-01   2.37269681e-02   0.00000000e+00
    3.50000000e+00]
 [  2.33732793e-03   5.36911845e-01   2.47414988e-02   0.00000000e+00
    3.50000000e+00]]

STEP 1:
[[  2.33732793e-03   5.36911845e-01   2.47414988e-02   0.00000000e+00
    3.50000000e+00]
 [  2.34455056e-03   5.48766136e-01   2.61307340e-02   0.00000000e+00
    3.50000000e+00]
 [  2.34921253e-03   5.56418002e-01   2.70274486e-02   0.00000000e+00
    3.50000000e+00]
 [  2.35295552e-03   5.62561393e-01   2.77474057e-02   0.00000000e+00
    3.50000000e+00]
 [  2.35612900e-03   5.67769885e-01   2.83577982e-02   0.00000000e+00
    3.50000000e+00]
 [  2.35913671e-03   5.72706580e-01   2.89363358e-02   0.00000000e+00
    3.50000000e+00]
 [  2.36184848e-03   5.77157438e-01   2.94579286e-02   0.00000000e+00
    3.50000000e+00]
 [  2.36428576e-03   5.81157625e-01   2.99267229e-02   0.00000000e+00
    3.50000000e+00]
 [  2.36649811e-03   5.84788799e-01   3.03522553e-02   0.00000000e+00
    3.50000000e+00]
 [  2.36850069e-03   5.88075638e-01   3.07374503e-02   0.00000000e+00
    3.50000000e+00]
 [  2.37031188e-03   5.91048360e-01   3.10858246e-02   0.00000000e+00
    3.50000000e+00]
 [  2.37195124e-03   5.93739033e-01   3.14011648e-02   0.00000000e+00
    3.50000000e+00]
 [  2.37343507e-03   5.96174240e-01   3.16865295e-02   0.00000000e+00
    3.50000000e+00]
 [  2.37477757e-03   5.98378003e-01   3.19447890e-02   0.00000000e+00
    3.50000000e+00]
 [  2.37599271e-03   6.00372255e-01   3.21785063e-02   0.00000000e+00
    3.50000000e+00]
 [  2.37709237e-03   6.02177143e-01   3.23900133e-02   0.00000000e+00
    3.50000000e+00]
 [  2.37808749e-03   6.03810549e-01   3.25814411e-02   0.00000000e+00
    3.50000000e+00]
 [  2.37898808e-03   6.05288684e-01   3.27546671e-02   0.00000000e+00
    3.50000000e+00]
 [  2.37980322e-03   6.06626391e-01   3.29114273e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38054083e-03   6.07837021e-01   3.30533013e-02   0.00000000e+00
    3.50000000e+00]]

STEP 2:
[[  2.38054083e-03   6.07837021e-01   3.30533013e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38155085e-03   6.09494865e-01   3.32475901e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38220277e-03   6.10564888e-01   3.33729908e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38272618e-03   6.11424029e-01   3.34736705e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38316995e-03   6.12152398e-01   3.35590392e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38359068e-03   6.12842739e-01   3.36399302e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38396996e-03   6.13465190e-01   3.37128714e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38431082e-03   6.14024580e-01   3.37784365e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38462002e-03   6.14532351e-01   3.38379294e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38490012e-03   6.14992023e-01   3.38918045e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38515344e-03   6.15407705e-01   3.39405239e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38538254e-03   6.15783989e-01   3.39846089e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38559023e-03   6.16124630e-01   3.40245292e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38577789e-03   6.16432726e-01   3.40606496e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38594785e-03   6.16711676e-01   3.40933353e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38610152e-03   6.16964042e-01   3.41229066e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38624075e-03   6.17192447e-01   3.41496766e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38636672e-03   6.17399156e-01   3.41739058e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38648057e-03   6.17586255e-01   3.41958255e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38658395e-03   6.17755532e-01   3.42156664e-02   0.00000000e+00
    3.50000000e+00]]

STEP 3:
[[  2.38658395e-03   6.17755532e-01   3.42156664e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38672504e-03   6.17987394e-01   3.42428386e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38681631e-03   6.18137062e-01   3.42603773e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38688942e-03   6.18257165e-01   3.42744514e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38695159e-03   6.18359029e-01   3.42863947e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38701049e-03   6.18455589e-01   3.42976972e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38706358e-03   6.18542612e-01   3.43078971e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38711108e-03   6.18620813e-01   3.43170688e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38715438e-03   6.18691802e-01   3.43253836e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38719350e-03   6.18756115e-01   3.43329161e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38722889e-03   6.18814230e-01   3.43397409e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38726102e-03   6.18866861e-01   3.43459100e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38728989e-03   6.18914485e-01   3.43514904e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38731620e-03   6.18957579e-01   3.43565345e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38733995e-03   6.18996501e-01   3.43611091e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38736160e-03   6.19031787e-01   3.43652368e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38738093e-03   6.19063735e-01   3.43689844e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38739862e-03   6.19092703e-01   3.43723521e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38741445e-03   6.19118810e-01   3.43754366e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38742889e-03   6.19142532e-01   3.43782082e-02   0.00000000e+00
    3.50000000e+00]]

STEP 4:
[[  2.38742889e-03   6.19142532e-01   3.43782082e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38744868e-03   6.19174957e-01   3.43820080e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38746149e-03   6.19195879e-01   3.43844593e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38747173e-03   6.19212687e-01   3.43864337e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38748034e-03   6.19226933e-01   3.43880877e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38748849e-03   6.19240463e-01   3.43896747e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38749594e-03   6.19252622e-01   3.43911126e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38750270e-03   6.19263530e-01   3.43923941e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38750875e-03   6.19273484e-01   3.43935490e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38751411e-03   6.19282424e-01   3.43946144e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38751899e-03   6.19290590e-01   3.43955532e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38752365e-03   6.19297981e-01   3.43964249e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38752761e-03   6.19304597e-01   3.43972072e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38753133e-03   6.19310617e-01   3.43979076e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38753459e-03   6.19316101e-01   3.43985558e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38753762e-03   6.19320989e-01   3.43991295e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38754041e-03   6.19325459e-01   3.43996435e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38754274e-03   6.19329453e-01   3.44001204e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38754507e-03   6.19333148e-01   3.44005451e-02   0.00000000e+00
    3.50000000e+00]
 [  2.38754717e-03   6.19336426e-01   3.44009399e-02   0.00000000e+00
    3.50000000e+00]]

