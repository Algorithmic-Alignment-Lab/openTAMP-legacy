{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(3),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7d933d50>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7d933d10>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd7daf5f10>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd7d937950>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbd7dca3250>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0., -3.,  0.,  0.,  0.,  0.,  0.,  0., -3.,  0.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd7d933fd0>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 0.001,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0.,  0.,  0., -3.,  0.])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 1000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 1000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [20],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd7daf5290>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 10,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd7d933fd0>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 0.001,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0.,  0.,  0., -3.,  0.])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 1000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 1000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [20],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd7daf5290>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 10,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [20],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 1000.0,
 'plan_f': <function <lambda> at 0x7fbd7d924668>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 1000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[ 0.          0.          0.         -3.          0.        ]
 [-0.18379618 -0.02435574 -0.04307175 -3.          0.        ]
 [-0.20035987 -0.026608   -0.04216141 -3.          0.        ]
 [-0.26243445 -0.03504863 -0.03874694 -3.          0.        ]
 [-0.33620793 -0.04508002 -0.03468899 -3.          0.        ]
 [-0.40048742 -0.05382046 -0.03115325 -3.          0.        ]
 [-0.46428967 -0.06249601 -0.02764378 -3.          0.        ]
 [-0.52761298 -0.07110643 -0.02416064 -3.          0.        ]
 [-0.58952647 -0.07952516 -0.02075506 -3.          0.        ]
 [-0.65029573 -0.0877883  -0.0174124  -3.          0.        ]
 [-0.70998102 -0.09590404 -0.01412939 -3.          0.        ]
 [-0.76865745 -0.10387778 -0.01031652 -3.          0.        ]
 [-0.8265968  -0.11173213 -0.00420497 -3.          0.        ]
 [-0.8832922  -0.11940774  0.00300204 -3.          0.        ]
 [-0.93761605 -0.12675753  0.01048663 -3.          0.        ]
 [-0.98905581 -0.13371499  0.01783207 -3.          0.        ]
 [-1.03755915 -0.14027442  0.02486367 -3.          0.        ]
 [-1.08319223 -0.14644533  0.03152203 -3.          0.        ]
 [-1.12607968 -0.15224484  0.03779726 -3.          0.        ]
 [-1.16637087 -0.15769318  0.04369943 -3.          0.        ]]

STEP 1:
[[-1.16637087 -0.15769318  0.04369943 -3.          0.        ]
 [-1.21810246 -0.16469398  0.05061521 -3.          0.        ]
 [-1.257429   -0.17001414  0.05610166 -3.          0.        ]
 [-1.29126382 -0.17458634  0.06143276 -3.          0.        ]
 [-1.32130933 -0.17864619  0.06620643 -3.          0.        ]
 [-1.35003662 -0.18252987  0.0705291  -3.          0.        ]
 [-1.37684953 -0.18615519  0.0745113  -3.          0.        ]
 [-1.40191174 -0.18954392  0.07821313 -3.          0.        ]
 [-1.42545009 -0.19272679  0.0816735  -3.          0.        ]
 [-1.44754791 -0.19571492  0.0849169  -3.          0.        ]
 [-1.46829522 -0.19852039  0.0879603  -3.          0.        ]
 [-1.4877795  -0.20115514  0.09081752 -3.          0.        ]
 [-1.50607824 -0.20362954  0.09350052 -3.          0.        ]
 [-1.52326369 -0.2059534   0.09602014 -3.          0.        ]
 [-1.53940356 -0.20813592  0.09838643 -3.          0.        ]
 [-1.55456161 -0.21018565  0.10060879 -3.          0.        ]
 [-1.56879771 -0.2121107   0.10269595 -3.          0.        ]
 [-1.58216798 -0.21391866  0.10465615 -3.          0.        ]
 [-1.59472489 -0.21561663  0.1064971  -3.          0.        ]
 [-1.60651803 -0.21721135  0.10822608 -3.          0.        ]]

STEP 2:
[[-1.60651803 -0.21721135  0.10822608 -3.          0.        ]
 [-1.62165713 -0.2192601   0.11025055 -3.          0.        ]
 [-1.63316584 -0.220817    0.1118563  -3.          0.        ]
 [-1.643067   -0.22215502  0.11341649 -3.          0.        ]
 [-1.65185952 -0.22334306  0.11481347 -3.          0.        ]
 [-1.66026604 -0.22447954  0.11607847 -3.          0.        ]
 [-1.66811228 -0.22554044  0.11724383 -3.          0.        ]
 [-1.67544627 -0.22653209  0.11832709 -3.          0.        ]
 [-1.68233454 -0.22746351  0.1193397  -3.          0.        ]
 [-1.68880129 -0.22833794  0.12028883 -3.          0.        ]
 [-1.6948725  -0.22915895  0.12117942 -3.          0.        ]
 [-1.70057428 -0.22992995  0.12201554 -3.          0.        ]
 [-1.70592916 -0.23065405  0.12280067 -3.          0.        ]
 [-1.71095836 -0.23133412  0.12353799 -3.          0.        ]
 [-1.71568143 -0.23197278  0.12423048 -3.          0.        ]
 [-1.72011745 -0.23257263  0.12488084 -3.          0.        ]
 [-1.72428346 -0.23313598  0.12549162 -3.          0.        ]
 [-1.72819591 -0.23366506  0.12606525 -3.          0.        ]
 [-1.73187077 -0.23416196  0.12660399 -3.          0.        ]
 [-1.73532176 -0.23462862  0.12710997 -3.          0.        ]]

STEP 3:
[[-1.73532176 -0.23462862  0.12710997 -3.          0.        ]
 [-1.73975194 -0.23522815  0.12770239 -3.          0.        ]
 [-1.74311996 -0.23568374  0.12817228 -3.          0.        ]
 [-1.74601734 -0.23607531  0.12862885 -3.          0.        ]
 [-1.74859023 -0.23642297  0.12903765 -3.          0.        ]
 [-1.75105035 -0.23675555  0.12940782 -3.          0.        ]
 [-1.75334644 -0.237066    0.12974885 -3.          0.        ]
 [-1.75549257 -0.23735619  0.13006586 -3.          0.        ]
 [-1.75750828 -0.23762874  0.13036221 -3.          0.        ]
 [-1.75940061 -0.23788464  0.13063994 -3.          0.        ]
 [-1.76117754 -0.23812489  0.13090056 -3.          0.        ]
 [-1.76284587 -0.23835048  0.13114524 -3.          0.        ]
 [-1.76441288 -0.23856242  0.13137498 -3.          0.        ]
 [-1.76588452 -0.23876141  0.13159072 -3.          0.        ]
 [-1.76726675 -0.23894832  0.13179338 -3.          0.        ]
 [-1.76856494 -0.23912387  0.1319837  -3.          0.        ]
 [-1.76978385 -0.2392887   0.13216242 -3.          0.        ]
 [-1.77092886 -0.23944353  0.1323303  -3.          0.        ]
 [-1.77200425 -0.23958893  0.13248795 -3.          0.        ]
 [-1.77301407 -0.2397255   0.13263601 -3.          0.        ]]

STEP 4:
[[-1.77301407 -0.2397255   0.13263601 -3.          0.        ]
 [-1.77431071 -0.23990096  0.13280937 -3.          0.        ]
 [-1.77529621 -0.24003428  0.13294691 -3.          0.        ]
 [-1.77614403 -0.24014884  0.13308051 -3.          0.        ]
 [-1.77689707 -0.2402506   0.13320014 -3.          0.        ]
 [-1.77761698 -0.24034794  0.13330847 -3.          0.        ]
 [-1.77828896 -0.24043879  0.13340828 -3.          0.        ]
 [-1.77891695 -0.24052371  0.13350105 -3.          0.        ]
 [-1.7795068  -0.24060346  0.13358775 -3.          0.        ]
 [-1.78006053 -0.24067834  0.13366905 -3.          0.        ]
 [-1.78058064 -0.24074866  0.13374531 -3.          0.        ]
 [-1.78106868 -0.24081467  0.1338169  -3.          0.        ]
 [-1.78152752 -0.24087669  0.13388413 -3.          0.        ]
 [-1.7819581  -0.24093494  0.13394728 -3.          0.        ]
 [-1.78236258 -0.24098963  0.13400656 -3.          0.        ]
 [-1.7827425  -0.24104099  0.13406229 -3.          0.        ]
 [-1.78309941 -0.24108925  0.13411459 -3.          0.        ]
 [-1.78343439 -0.24113457  0.13416374 -3.          0.        ]
 [-1.7837491  -0.24117713  0.13420987 -3.          0.        ]
 [-1.78404474 -0.24121711  0.1342532  -3.          0.        ]]

