{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 2,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(2),
           'get_hl_plan': <function hl_plan_for_state at 0x7f5e5ab91f50>,
           'get_plan': <function get_plan at 0x7f5e5ab1a0c8>,
           'hist_len': 10,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7f5e4a550950>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7f5e4a550850>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7f5e4a522dd0>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7f5e5218a2d0>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 30,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7f5e4ac80650>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]},
                       {'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0., -1.,  2.,  0.,  0.,  0.,  0.,  0., -1.,  2.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),
                  array([ 0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7f5e4a522590>,
                         'conditions': 2,
                         'cost': {'type': <class 'policy_hooks.traj_constr_cost.TrajConstrCost'>},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 0.001,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7f5e5ab2f2a8>,
                                             'x0': [array([ 0.,  0.,  0., -1.,  2.]),
                                                    array([ 0.,  0.,  0.,  0.,  2.])]},
                         'iterations': 10,
                         'kl_step': 1.0,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 1000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7f5e7478d938>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 30,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 5000,
                                        'lr': 0.0001,
                                        'network_model': <function tf_network at 0x7f5e7478d938>,
                                        'network_params': {'dim_hidden': [100],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 30,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7f5e4ac5c110>,
                                        'primitive_network_model': <function tf_classification_network at 0x7f5e5ab42b90>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 0.01,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7f5e4a522590>,
                           'conditions': 2,
                           'cost': {'type': <class 'policy_hooks.traj_constr_cost.TrajConstrCost'>},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 0.001,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7f5e5ab2f2a8>,
                                               'x0': [array([ 0.,  0.,  0., -1.,  2.]),
                                                      array([ 0.,  0.,  0.,  0.,  2.])]},
                           'iterations': 10,
                           'kl_step': 1.0,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 1000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7f5e7478d938>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 30,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 5000,
                                          'lr': 0.0001,
                                          'network_model': <function tf_network at 0x7f5e7478d938>,
                                          'network_params': {'dim_hidden': [100],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 30,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7f5e4ac5c110>,
                                          'primitive_network_model': <function tf_classification_network at 0x7f5e5ab42b90>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 0.01,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 2,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_02-43',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7f5e5ab1a410>,
 'dQ': 3,
 'dim_hidden': [100],
 'goal_f': <function goal_f at 0x7f5e5ab1a488>,
 'gui_on': False,
 'hist_len': 10,
 'iterations': 10,
 'lr': 0.0001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 2,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 1000.0,
 'plan_f': <function <lambda> at 0x7f5e3159e7d0>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7f5e5ab1a320>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 5000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'policy_hooks.traj_constr_cost.TrajConstrCost'>

STEP 0:
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00  -1.00000000e+00
    2.00000000e+00]
 [ -4.28577932e-03   1.61945194e-01  -2.28535458e-02  -1.00000000e+00
    2.00000000e+00]
 [ -4.28577932e-03   1.61945194e-01  -2.28535458e-02  -1.00000000e+00
    2.00000000e+00]
 [ -4.82811546e-03   1.67493358e-01  -2.18424071e-02  -1.00000000e+00
    2.00000000e+00]
 [ -6.71531633e-03   1.84655651e-01  -1.86989233e-02  -1.00000000e+00
    2.00000000e+00]
 [ -1.13084158e-02   2.03793347e-01  -1.50069091e-02  -1.00000000e+00
    2.00000000e+00]
 [ -1.57535374e-02   2.21977249e-01  -1.14928233e-02  -1.00000000e+00
    2.00000000e+00]
 [ -2.04229187e-02   2.39431769e-01  -8.09034426e-03  -1.00000000e+00
    2.00000000e+00]
 [ -2.55967788e-02   2.55999446e-01  -4.80641425e-03  -1.00000000e+00
    2.00000000e+00]
 [ -3.06125004e-02   2.71282583e-01  -1.75914541e-03  -1.00000000e+00
    2.00000000e+00]
 [ -3.56761850e-02   2.86027819e-01   1.19747221e-03  -1.00000000e+00
    2.00000000e+00]
 [ -4.09264714e-02   3.01122576e-01   4.22907993e-03  -1.00000000e+00
    2.00000000e+00]
 [ -4.52460423e-02   3.11379224e-01   6.34466298e-03  -1.00000000e+00
    2.00000000e+00]
 [ -4.91697378e-02   3.20020020e-01   8.14798474e-03  -1.00000000e+00
    2.00000000e+00]
 [ -5.30278049e-02   3.28081429e-01   9.84498486e-03  -1.00000000e+00
    2.00000000e+00]
 [ -5.68168312e-02   3.35614741e-01   1.14444084e-02  -1.00000000e+00
    2.00000000e+00]
 [ -6.04626313e-02   3.42657566e-01   1.29473545e-02  -1.00000000e+00
    2.00000000e+00]
 [ -6.39782026e-02   3.49265635e-01   1.43645331e-02  -1.00000000e+00
    2.00000000e+00]
 [ -6.73554763e-02   3.55477750e-01   1.57021433e-02  -1.00000000e+00
    2.00000000e+00]
 [ -7.05672577e-02   3.61302018e-01   1.69596076e-02  -1.00000000e+00
    2.00000000e+00]]

STEP 1:
[[-0.07056726  0.36130202  0.01695961 -1.          2.        ]
 [-0.07571735  0.36975881  0.01882141 -1.          2.        ]
 [-0.07879239  0.37540698  0.02003795 -1.          2.        ]
 [-0.08139946  0.37999552  0.0210343  -1.          2.        ]
 [-0.08377446  0.38401207  0.02191332 -1.          2.        ]
 [-0.08600841  0.38774347  0.02273198 -1.          2.        ]
 [-0.08810097  0.39120063  0.02349215 -1.          2.        ]
 [-0.09006258  0.39441597  0.02420031 -1.          2.        ]
 [-0.09190309  0.39741057  0.02486083 -1.          2.        ]
 [-0.09363157  0.40019464  0.02547621 -1.          2.        ]
 [-0.09524303  0.40278894  0.0260497  -1.          2.        ]
 [-0.09674308  0.4051916   0.02658139 -1.          2.        ]
 [-0.09819328  0.4074977   0.02709248 -1.          2.        ]
 [-0.09954538  0.40965551  0.02757035 -1.          2.        ]
 [-0.10080808  0.41166574  0.02801578 -1.          2.        ]
 [-0.10199091  0.41354412  0.02843219 -1.          2.        ]
 [-0.10309874  0.41529977  0.02882157 -1.          2.        ]
 [-0.1041364   0.41694102  0.02918573 -1.          2.        ]
 [-0.10510863  0.41847599  0.02952644 -1.          2.        ]
 [-0.10601963  0.41991195  0.02984527 -1.          2.        ]]

STEP 2:
[[-0.10601963  0.41991195  0.02984527 -1.          2.        ]
 [-0.10746942  0.42199856  0.03031791 -1.          2.        ]
 [-0.10833216  0.42345288  0.03063638 -1.          2.        ]
 [-0.10906927  0.42465925  0.03090217 -1.          2.        ]
 [-0.10973916  0.42572609  0.03113854 -1.          2.        ]
 [-0.11036544  0.42672154  0.03135917 -1.          2.        ]
 [-0.11094894  0.42764574  0.03156418 -1.          2.        ]
 [-0.11149292  0.4285056   0.03175499 -1.          2.        ]
 [-0.112001    0.42930636  0.03193279 -1.          2.        ]
 [-0.11247668  0.43005115  0.0320984  -1.          2.        ]
 [-0.11291946  0.4307462   0.03225286 -1.          2.        ]
 [-0.11333174  0.43139195  0.03239644 -1.          2.        ]
 [-0.11373021  0.43201357  0.03253477 -1.          2.        ]
 [-0.11410185  0.43259734  0.03266448 -1.          2.        ]
 [-0.11444873  0.43314245  0.03278559 -1.          2.        ]
 [-0.11477336  0.43365249  0.03289892 -1.          2.        ]
 [-0.11507708  0.43412954  0.03300492 -1.          2.        ]
 [-0.11536129  0.43457565  0.03310406 -1.          2.        ]
 [-0.11562736  0.43499291  0.03319682 -1.          2.        ]
 [-0.11587653  0.43538332  0.03328361 -1.          2.        ]]

STEP 3:
[[-0.11587653  0.43538332  0.03328361 -1.          2.        ]
 [-0.11627305  0.43595091  0.03341233 -1.          2.        ]
 [-0.11650885  0.43634695  0.03349913 -1.          2.        ]
 [-0.11671032  0.43667564  0.0335716  -1.          2.        ]
 [-0.11689343  0.43696645  0.03363606 -1.          2.        ]
 [-0.11706456  0.43723786  0.03369625 -1.          2.        ]
 [-0.11722398  0.43748993  0.03375218 -1.          2.        ]
 [-0.11737259  0.43772444  0.03380424 -1.          2.        ]
 [-0.11751139  0.43794286  0.03385276 -1.          2.        ]
 [-0.11764132  0.43814605  0.03389794 -1.          2.        ]
 [-0.11776223  0.43833569  0.03394009 -1.          2.        ]
 [-0.11787483  0.43851188  0.03397927 -1.          2.        ]
 [-0.11798365  0.43868145  0.03401703 -1.          2.        ]
 [-0.11808512  0.43884078  0.03405242 -1.          2.        ]
 [-0.11817985  0.43898952  0.03408549 -1.          2.        ]
 [-0.1182685   0.43912876  0.03411641 -1.          2.        ]
 [-0.11835144  0.43925893  0.03414535 -1.          2.        ]
 [-0.11842905  0.43938071  0.03417242 -1.          2.        ]
 [-0.11850167  0.43949461  0.03419773 -1.          2.        ]
 [-0.1185697   0.43960118  0.03422143 -1.          2.        ]]

STEP 4:
[[-0.1185697   0.43960118  0.03422143 -1.          2.        ]
 [-0.11867798  0.4397561   0.03425657 -1.          2.        ]
 [-0.11874235  0.43986422  0.03428026 -1.          2.        ]
 [-0.11879736  0.43995395  0.03430004 -1.          2.        ]
 [-0.11884734  0.44003335  0.03431763 -1.          2.        ]
 [-0.11889406  0.44010743  0.03433407 -1.          2.        ]
 [-0.1189376   0.44017625  0.03434934 -1.          2.        ]
 [-0.11897819  0.44024026  0.03436356 -1.          2.        ]
 [-0.11901605  0.44029993  0.0343768  -1.          2.        ]
 [-0.11905152  0.44035536  0.03438914 -1.          2.        ]
 [-0.11908454  0.44040713  0.03440064 -1.          2.        ]
 [-0.11911529  0.4404552   0.03441134 -1.          2.        ]
 [-0.11914498  0.44050154  0.03442165 -1.          2.        ]
 [-0.11917271  0.44054505  0.03443131 -1.          2.        ]
 [-0.11919856  0.44058564  0.03444034 -1.          2.        ]
 [-0.11922276  0.44062361  0.03444879 -1.          2.        ]
 [-0.1192454   0.44065922  0.03445668 -1.          2.        ]
 [-0.11926659  0.44069242  0.03446407 -1.          2.        ]
 [-0.11928643  0.44072351  0.03447098 -1.          2.        ]
 [-0.11930501  0.4407526   0.03447745 -1.          2.        ]]

