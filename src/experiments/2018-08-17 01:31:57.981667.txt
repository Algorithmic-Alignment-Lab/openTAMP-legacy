{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(27),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7d0fb490>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7d0fba10>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd9d261950>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd7d0fb910>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbd7c03f850>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0., -3.,  0.,  0.,  0.,  0.,  0.,  0., -3.,  0.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd9d261310>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 0.001,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0.,  0.,  0., -3.,  0.])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 1000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 5000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [100],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbda608e5d0>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 10,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd9d261310>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 0.001,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0.,  0.,  0., -3.,  0.])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 1000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 5000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [100],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbda608e5d0>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 10,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [100],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 1000.0,
 'plan_f': <function <lambda> at 0x7fbd7d303668>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 5000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00  -3.00000000e+00
    0.00000000e+00]
 [ -1.77694410e-01  -2.29945555e-02  -4.05639820e-02  -3.00000000e+00
    0.00000000e+00]
 [ -1.96619734e-01  -2.55770311e-02  -4.02484350e-02  -3.00000000e+00
    0.00000000e+00]
 [ -2.48465031e-01  -3.26495953e-02  -3.87844704e-02  -3.00000000e+00
    0.00000000e+00]
 [ -3.10753882e-01  -4.11420204e-02  -3.55466530e-02  -3.00000000e+00
    0.00000000e+00]
 [ -3.66695404e-01  -4.87688892e-02  -3.25853825e-02  -3.00000000e+00
    0.00000000e+00]
 [ -4.21705127e-01  -5.62687851e-02  -2.96946615e-02  -3.00000000e+00
    0.00000000e+00]
 [ -4.76078838e-01  -6.36819825e-02  -2.68396176e-02  -3.00000000e+00
    0.00000000e+00]
 [ -5.29271722e-01  -7.09341690e-02  -2.40448378e-02  -3.00000000e+00
    0.00000000e+00]
 [ -5.81406772e-01  -7.80421644e-02  -2.13058162e-02  -3.00000000e+00
    0.00000000e+00]
 [ -6.32845461e-01  -8.50469247e-02  -1.73602812e-02  -3.00000000e+00
    0.00000000e+00]
 [ -6.83634400e-01  -9.19542983e-02  -1.21114645e-02  -3.00000000e+00
    0.00000000e+00]
 [ -7.33122587e-01  -9.86815691e-02  -6.48630038e-03  -3.00000000e+00
    0.00000000e+00]
 [ -7.80773640e-01  -1.05158195e-01  -9.22851264e-04  -3.00000000e+00
    0.00000000e+00]
 [ -8.26495290e-01  -1.11372404e-01   4.43523750e-03  -3.00000000e+00
    0.00000000e+00]
 [ -8.70343804e-01  -1.17332101e-01   9.56675783e-03  -3.00000000e+00
    0.00000000e+00]
 [ -9.12395239e-01  -1.23047575e-01   1.44817382e-02  -3.00000000e+00
    0.00000000e+00]
 [ -9.52726841e-01  -1.28529355e-01   1.91930793e-02  -3.00000000e+00
    0.00000000e+00]
 [ -9.91412163e-01  -1.33787334e-01   2.37112753e-02  -3.00000000e+00
    0.00000000e+00]
 [ -1.02851868e+00  -1.38830751e-01   2.80450024e-02  -3.00000000e+00
    0.00000000e+00]]

STEP 1:
[[-1.02851868 -0.13883075  0.028045   -3.          0.        ]
 [-1.07876623 -0.14566323  0.03344138 -3.          0.        ]
 [-1.11615682 -0.15074566  0.03774792 -3.          0.        ]
 [-1.14943564 -0.15526715  0.04190364 -3.          0.        ]
 [-1.17977667 -0.15938956  0.0456701  -3.          0.        ]
 [-1.20930135 -0.16340223  0.04915771 -3.          0.        ]
 [-1.23756516 -0.16724372  0.05246289 -3.          0.        ]
 [-1.26461339 -0.17092001  0.05562224 -3.          0.        ]
 [-1.2905699  -0.17444798  0.05865205 -3.          0.        ]
 [-1.31547046 -0.17783242  0.0615593  -3.          0.        ]
 [-1.33935428 -0.18107861  0.06434852 -3.          0.        ]
 [-1.3622638  -0.18419242  0.06702419 -3.          0.        ]
 [-1.38423884 -0.18717921  0.06959073 -3.          0.        ]
 [-1.40531707 -0.19004413  0.07205255 -3.          0.        ]
 [-1.42553556 -0.19279212  0.07441391 -3.          0.        ]
 [-1.444929   -0.19542801  0.07667893 -3.          0.        ]
 [-1.46353102 -0.19795635  0.07885155 -3.          0.        ]
 [-1.48137403 -0.20038155  0.08093551 -3.          0.        ]
 [-1.4984889  -0.20270774  0.08293442 -3.          0.        ]
 [-1.51490581 -0.20493904  0.08485177 -3.          0.        ]]

STEP 2:
[[-1.51490581 -0.20493904  0.08485177 -3.          0.        ]
 [-1.53713596 -0.20796186  0.08723928 -3.          0.        ]
 [-1.55367827 -0.21021041  0.08914453 -3.          0.        ]
 [-1.56840134 -0.21221077  0.09098312 -3.          0.        ]
 [-1.58182478 -0.21403462  0.09264944 -3.          0.        ]
 [-1.59488678 -0.21580991  0.0941924  -3.          0.        ]
 [-1.60739112 -0.21750948  0.0956547  -3.          0.        ]
 [-1.61935782 -0.21913585  0.09705247 -3.          0.        ]
 [-1.63084114 -0.22069669  0.09839289 -3.          0.        ]
 [-1.64185762 -0.22219402  0.09967907 -3.          0.        ]
 [-1.65242422 -0.22363016  0.10091308 -3.          0.        ]
 [-1.66255975 -0.22500777  0.10209683 -3.          0.        ]
 [-1.67228186 -0.22632915  0.10323231 -3.          0.        ]
 [-1.68160725 -0.22759667  0.10432146 -3.          0.        ]
 [-1.69055235 -0.22881243  0.10536619 -3.          0.        ]
 [-1.69913232 -0.22997865  0.10636827 -3.          0.        ]
 [-1.70736253 -0.23109719  0.10732949 -3.          0.        ]
 [-1.71525633 -0.23217013  0.10825147 -3.          0.        ]
 [-1.72282851 -0.23319933  0.10913579 -3.          0.        ]
 [-1.73009145 -0.2341865   0.10998408 -3.          0.        ]]

STEP 3:
[[-1.73009145 -0.2341865   0.10998408 -3.          0.        ]
 [-1.73992658 -0.23552388  0.11104037 -3.          0.        ]
 [-1.74724531 -0.23651868  0.1118833  -3.          0.        ]
 [-1.75375915 -0.23740369  0.11269675 -3.          0.        ]
 [-1.75969791 -0.23821053  0.11343399 -3.          0.        ]
 [-1.76547682 -0.23899597  0.11411661 -3.          0.        ]
 [-1.77100861 -0.23974788  0.11476351 -3.          0.        ]
 [-1.77630317 -0.2404674   0.11538191 -3.          0.        ]
 [-1.78138363 -0.24115792  0.1159749  -3.          0.        ]
 [-1.78625751 -0.24182042  0.11654395 -3.          0.        ]
 [-1.79093242 -0.24245584  0.1170899  -3.          0.        ]
 [-1.79541671 -0.24306533  0.11761363 -3.          0.        ]
 [-1.7997179  -0.24364993  0.11811601 -3.          0.        ]
 [-1.80384386 -0.24421069  0.11859789 -3.          0.        ]
 [-1.80780101 -0.24474856  0.1190601  -3.          0.        ]
 [-1.81159711 -0.24526447  0.11950344 -3.          0.        ]
 [-1.81523812 -0.24575937  0.11992869 -3.          0.        ]
 [-1.81873071 -0.24623406  0.12033656 -3.          0.        ]
 [-1.82208049 -0.24668938  0.12072782 -3.          0.        ]
 [-1.82529354 -0.24712613  0.12110312 -3.          0.        ]]

STEP 4:
[[-1.82529354 -0.24712613  0.12110312 -3.          0.        ]
 [-1.8296448  -0.2477178   0.12157047 -3.          0.        ]
 [-1.83288264 -0.24815792  0.12194335 -3.          0.        ]
 [-1.83576477 -0.24854946  0.12230322 -3.          0.        ]
 [-1.8383919  -0.24890643  0.12262936 -3.          0.        ]
 [-1.8409487  -0.2492539   0.12293139 -3.          0.        ]
 [-1.84339619 -0.24958658  0.12321758 -3.          0.        ]
 [-1.84573877 -0.24990493  0.12349118 -3.          0.        ]
 [-1.84798634 -0.2502104   0.12375355 -3.          0.        ]
 [-1.85014248 -0.25050351  0.1240053  -3.          0.        ]
 [-1.85221088 -0.25078461  0.12424685 -3.          0.        ]
 [-1.85419476 -0.25105423  0.12447855 -3.          0.        ]
 [-1.85609806 -0.25131288  0.12470081 -3.          0.        ]
 [-1.85792291 -0.25156102  0.12491398 -3.          0.        ]
 [-1.85967374 -0.25179896  0.12511848 -3.          0.        ]
 [-1.8613534  -0.25202718  0.12531464 -3.          0.        ]
 [-1.86296403 -0.25224617  0.12550279 -3.          0.        ]
 [-1.86450911 -0.25245619  0.12568322 -3.          0.        ]
 [-1.86599112 -0.25265759  0.12585634 -3.          0.        ]
 [-1.86741292 -0.25285083  0.12602235 -3.          0.        ]]

