{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(19),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7d881d90>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7d881d50>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd7d896e90>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd7d89a990>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbd1fd687d0>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd7d881fd0>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 0.001,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0.,  0.,  0., -2.,  0.])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 1000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 1000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [100],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd7d889050>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 10,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd7d881fd0>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 0.001,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0.,  0.,  0., -2.,  0.])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 1000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 1000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [100],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd7d889050>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 10,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [100],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 1000.0,
 'plan_f': <function <lambda> at 0x7fbd243897d0>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 1000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00  -2.00000000e+00
    0.00000000e+00]
 [ -1.47917926e-01  -2.90488061e-02  -4.56764102e-02  -2.00000000e+00
    0.00000000e+00]
 [ -1.66280672e-01  -3.27758454e-02  -4.39028516e-02  -2.00000000e+00
    0.00000000e+00]
 [ -2.17954889e-01  -4.32637334e-02  -3.88467200e-02  -2.00000000e+00
    0.00000000e+00]
 [ -2.79398441e-01  -5.57344332e-02  -3.28355208e-02  -2.00000000e+00
    0.00000000e+00]
 [ -3.30780745e-01  -6.61630780e-02  -2.78082471e-02  -2.00000000e+00
    0.00000000e+00]
 [ -3.80512536e-01  -7.62567446e-02  -2.29429025e-02  -2.00000000e+00
    0.00000000e+00]
 [ -4.28940386e-01  -8.60857442e-02  -1.82051137e-02  -2.00000000e+00
    0.00000000e+00]
 [ -4.75047410e-01  -9.54437107e-02  -1.36943273e-02  -2.00000000e+00
    0.00000000e+00]
 [ -5.19447803e-01  -1.04444779e-01  -6.98882341e-03  -2.00000000e+00
    0.00000000e+00]
 [ -5.62223494e-01  -1.13110356e-01   8.36361200e-04  -2.00000000e+00
    0.00000000e+00]
 [ -6.02567852e-01  -1.21281199e-01   8.70123133e-03  -2.00000000e+00
    0.00000000e+00]
 [ -6.40139639e-01  -1.28889948e-01   1.61596611e-02  -2.00000000e+00
    0.00000000e+00]
 [ -6.75048232e-01  -1.35959283e-01   2.31060609e-02  -2.00000000e+00
    0.00000000e+00]
 [ -7.07465112e-01  -1.42524078e-01   2.95515880e-02  -2.00000000e+00
    0.00000000e+00]
 [ -7.37563372e-01  -1.48619294e-01   3.55319455e-02  -2.00000000e+00
    0.00000000e+00]
 [ -7.65511751e-01  -1.54279158e-01   4.10832763e-02  -2.00000000e+00
    0.00000000e+00]
 [ -7.91465700e-01  -1.59535155e-01   4.62378114e-02  -2.00000000e+00
    0.00000000e+00]
 [ -8.15567851e-01  -1.64416119e-01   5.10244742e-02  -2.00000000e+00
    0.00000000e+00]
 [ -8.37950408e-01  -1.68948844e-01   5.54696470e-02  -2.00000000e+00
    0.00000000e+00]]

STEP 1:
[[-0.83795041 -0.16894884  0.05546965 -2.          0.        ]
 [-0.86689025 -0.17481139  0.0607997  -2.          0.        ]
 [-0.88822466 -0.17913228  0.0649431  -2.          0.        ]
 [-0.90627307 -0.18278611  0.06879143 -2.          0.        ]
 [-0.9218902  -0.18594779  0.0721117  -2.          0.        ]
 [-0.93678844 -0.1889648   0.07509448 -2.          0.        ]
 [-0.95056754 -0.19175516  0.07783424 -2.          0.        ]
 [-0.96330029 -0.19433369  0.08036643 -2.          0.        ]
 [-0.9751426  -0.1967319   0.08271691 -2.          0.        ]
 [-0.98614174 -0.19895937  0.08490054 -2.          0.        ]
 [-0.99635375 -0.20102744  0.08692862 -2.          0.        ]
 [-1.00583804 -0.20294809  0.08881211 -2.          0.        ]
 [-1.0146457  -0.20473176  0.09056133 -2.          0.        ]
 [-1.022825   -0.20638816  0.09218572 -2.          0.        ]
 [-1.03042078 -0.20792638  0.09369421 -2.          0.        ]
 [-1.03747451 -0.20935486  0.09509513 -2.          0.        ]
 [-1.04402518 -0.21068144  0.09639606 -2.          0.        ]
 [-1.05010819 -0.21191335  0.0976042  -2.          0.        ]
 [-1.05575752 -0.21305738  0.09872612 -2.          0.        ]
 [-1.06100368 -0.21411976  0.09976803 -2.          0.        ]]

STEP 2:
[[-1.06100368 -0.21411976  0.09976803 -2.          0.        ]
 [-1.06778669 -0.21549387  0.10101731 -2.          0.        ]
 [-1.07278705 -0.21650663  0.10198845 -2.          0.        ]
 [-1.07701731 -0.217363    0.10289045 -2.          0.        ]
 [-1.08067763 -0.21810403  0.10366865 -2.          0.        ]
 [-1.08416963 -0.21881117  0.10436775 -2.          0.        ]
 [-1.08739924 -0.2194652   0.10500991 -2.          0.        ]
 [-1.09038377 -0.22006957  0.10560341 -2.          0.        ]
 [-1.0931592  -0.22063166  0.10615434 -2.          0.        ]
 [-1.09573722 -0.22115372  0.10666613 -2.          0.        ]
 [-1.0981307  -0.22163846  0.10714146 -2.          0.        ]
 [-1.10035372 -0.22208866  0.10758293 -2.          0.        ]
 [-1.10241818 -0.22250673  0.1079929  -2.          0.        ]
 [-1.10433507 -0.22289494  0.10837367 -2.          0.        ]
 [-1.10611546 -0.22325547  0.10872723 -2.          0.        ]
 [-1.10776901 -0.2235903   0.10905559 -2.          0.        ]
 [-1.10930419 -0.22390123  0.10936053 -2.          0.        ]
 [-1.11073017 -0.22418995  0.10964371 -2.          0.        ]
 [-1.11205411 -0.22445811  0.10990667 -2.          0.        ]
 [-1.11328363 -0.22470713  0.11015086 -2.          0.        ]]

STEP 3:
[[-1.11328363 -0.22470713  0.11015086 -2.          0.        ]
 [-1.11487341 -0.22502916  0.11044365 -2.          0.        ]
 [-1.11604548 -0.22526653  0.11067127 -2.          0.        ]
 [-1.11703706 -0.22546726  0.11088265 -2.          0.        ]
 [-1.11789477 -0.22564092  0.11106509 -2.          0.        ]
 [-1.11871326 -0.22580668  0.11122893 -2.          0.        ]
 [-1.11947024 -0.22595999  0.1113794  -2.          0.        ]
 [-1.12016988 -0.22610162  0.11151852 -2.          0.        ]
 [-1.12082028 -0.22623338  0.11164768 -2.          0.        ]
 [-1.12142467 -0.22635573  0.11176763 -2.          0.        ]
 [-1.12198567 -0.22646937  0.11187901 -2.          0.        ]
 [-1.12250662 -0.22657487  0.11198252 -2.          0.        ]
 [-1.12299037 -0.22667289  0.11207862 -2.          0.        ]
 [-1.12343979 -0.22676384  0.11216784 -2.          0.        ]
 [-1.12385702 -0.22684833  0.1122507  -2.          0.        ]
 [-1.12424445 -0.22692682  0.11232769 -2.          0.        ]
 [-1.12460423 -0.22699967  0.11239913 -2.          0.        ]
 [-1.12493849 -0.22706734  0.1124655  -2.          0.        ]
 [-1.12524891 -0.22713017  0.1125271  -2.          0.        ]
 [-1.12553716 -0.22718857  0.11258438 -2.          0.        ]]

STEP 4:
[[-1.12553716 -0.22718857  0.11258438 -2.          0.        ]
 [-1.12590981 -0.22726406  0.11265302 -2.          0.        ]
 [-1.12618446 -0.22731972  0.11270636 -2.          0.        ]
 [-1.1264168  -0.22736678  0.11275591 -2.          0.        ]
 [-1.12661803 -0.22740746  0.11279866 -2.          0.        ]
 [-1.1268096  -0.22744629  0.11283711 -2.          0.        ]
 [-1.12698698 -0.22748223  0.11287236 -2.          0.        ]
 [-1.12715101 -0.22751543  0.11290492 -2.          0.        ]
 [-1.1273036  -0.22754629  0.11293519 -2.          0.        ]
 [-1.1274451  -0.22757499  0.11296329 -2.          0.        ]
 [-1.12757659 -0.2276016   0.11298941 -2.          0.        ]
 [-1.12769866 -0.22762635  0.11301365 -2.          0.        ]
 [-1.12781215 -0.22764933  0.1130362  -2.          0.        ]
 [-1.12791753 -0.22767065  0.11305712 -2.          0.        ]
 [-1.12801528 -0.22769043  0.11307655 -2.          0.        ]
 [-1.12810612 -0.22770883  0.11309457 -2.          0.        ]
 [-1.1281904  -0.22772594  0.11311132 -2.          0.        ]
 [-1.12826872 -0.22774178  0.11312687 -2.          0.        ]
 [-1.12834167 -0.2277565   0.11314134 -2.          0.        ]
 [-1.12840915 -0.22777021  0.11315474 -2.          0.        ]]

