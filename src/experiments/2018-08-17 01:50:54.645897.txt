{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(31),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd931f0cd0>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd931f0c90>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd931ef950>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd931c1910>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbd7cb888d0>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0.,  1.,  2.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd931f0f90>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 1.0,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0.,  0.,  0.,  1.,  2.])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 1000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 5000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [100],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd931d72d0>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 10,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd931f0f90>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 1.0,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0.,  0.,  0.,  1.,  2.])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 1000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 5000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [100],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd931d72d0>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 10,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [100],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 1000.0,
 'plan_f': <function <lambda> at 0x7fbd7d8f8668>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 5000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[ 0.          0.          0.          1.          2.        ]
 [ 0.173518    0.23885921  0.00638237  1.          2.        ]
 [ 0.25229955  0.36087614  0.02170115  1.          2.        ]
 [ 0.31253898  0.45420134  0.03341736  1.          2.        ]
 [ 0.36929628  0.54218256  0.04446185  1.          2.        ]
 [ 0.41308975  0.61007226  0.05298415  1.          2.        ]
 [ 0.44814569  0.66441607  0.05980603  1.          2.        ]
 [ 0.47687125  0.70894903  0.06539628  1.          2.        ]
 [ 0.50002652  0.74484581  0.06990244  1.          2.        ]
 [ 0.51872653  0.77383554  0.07354155  1.          2.        ]
 [ 0.53386521  0.79730463  0.07648765  1.          2.        ]
 [ 0.54610497  0.81627935  0.07886957  1.          2.        ]
 [ 0.55600119  0.83162117  0.08079543  1.          2.        ]
 [ 0.56400448  0.84402835  0.08235293  1.          2.        ]
 [ 0.57047629  0.85406142  0.0836124   1.          2.        ]
 [ 0.57570964  0.86217451  0.08463085  1.          2.        ]
 [ 0.57994169  0.86873513  0.0854544   1.          2.        ]
 [ 0.58336395  0.87404042  0.08612038  1.          2.        ]
 [ 0.58613122  0.87833059  0.08665893  1.          2.        ]
 [ 0.58836901  0.88179964  0.08709443  1.          2.        ]]

STEP 1:
[[ 0.58836901  0.88179964  0.08709443  1.          2.        ]
 [ 0.59108633  0.88601261  0.08762326  1.          2.        ]
 [ 0.59255093  0.88828307  0.08790828  1.          2.        ]
 [ 0.5935756   0.88987154  0.08810766  1.          2.        ]
 [ 0.59436208  0.89109039  0.0882607   1.          2.        ]
 [ 0.59503144  0.89212823  0.08839097  1.          2.        ]
 [ 0.59556758  0.89295942  0.08849529  1.          2.        ]
 [ 0.59599853  0.89362746  0.08857916  1.          2.        ]
 [ 0.5963484   0.89416999  0.08864728  1.          2.        ]
 [ 0.59663129  0.89460856  0.08870231  1.          2.        ]
 [ 0.59685987  0.89496285  0.0887468   1.          2.        ]
 [ 0.59704477  0.89524949  0.08878279  1.          2.        ]
 [ 0.59719437  0.89548123  0.08881187  1.          2.        ]
 [ 0.59731525  0.8956688   0.0888354   1.          2.        ]
 [ 0.597413    0.89582032  0.08885443  1.          2.        ]
 [ 0.59749216  0.89594293  0.08886981  1.          2.        ]
 [ 0.59755599  0.89604199  0.08888227  1.          2.        ]
 [ 0.59760767  0.89612216  0.08889233  1.          2.        ]
 [ 0.59764951  0.89618695  0.08890046  1.          2.        ]
 [ 0.59768331  0.89623934  0.08890703  1.          2.        ]]

STEP 2:
[[ 0.59768331  0.89623934  0.08890703  1.          2.        ]
 [ 0.59772438  0.896303    0.08891503  1.          2.        ]
 [ 0.59774649  0.89633733  0.08891933  1.          2.        ]
 [ 0.59776199  0.89636129  0.08892234  1.          2.        ]
 [ 0.59777379  0.89637977  0.08892467  1.          2.        ]
 [ 0.59778398  0.89639544  0.08892663  1.          2.        ]
 [ 0.59779209  0.89640796  0.08892821  1.          2.        ]
 [ 0.59779859  0.89641798  0.08892947  1.          2.        ]
 [ 0.59780383  0.89642614  0.0889305   1.          2.        ]
 [ 0.59780812  0.89643276  0.08893133  1.          2.        ]
 [ 0.59781158  0.89643812  0.08893199  1.          2.        ]
 [ 0.59781432  0.89644247  0.08893254  1.          2.        ]
 [ 0.59781659  0.89644599  0.08893298  1.          2.        ]
 [ 0.59781843  0.89644885  0.08893333  1.          2.        ]
 [ 0.59781986  0.89645118  0.08893362  1.          2.        ]
 [ 0.59782106  0.89645302  0.08893386  1.          2.        ]
 [ 0.59782207  0.89645445  0.08893406  1.          2.        ]
 [ 0.59782284  0.89645571  0.0889342   1.          2.        ]
 [ 0.59782356  0.89645666  0.08893431  1.          2.        ]
 [ 0.59782398  0.89645749  0.08893442  1.          2.        ]]

STEP 3:
[[ 0.59782398  0.89645749  0.08893442  1.          2.        ]
 [ 0.59782463  0.89645845  0.08893453  1.          2.        ]
 [ 0.59782487  0.89645898  0.08893461  1.          2.        ]
 [ 0.59782523  0.89645928  0.08893465  1.          2.        ]
 [ 0.59782541  0.89645964  0.0889347   1.          2.        ]
 [ 0.59782553  0.89645988  0.08893473  1.          2.        ]
 [ 0.59782571  0.89646006  0.08893474  1.          2.        ]
 [ 0.59782583  0.89646012  0.08893476  1.          2.        ]
 [ 0.59782583  0.89646018  0.08893478  1.          2.        ]
 [ 0.59782588  0.89646029  0.08893479  1.          2.        ]
 [ 0.59782588  0.89646035  0.08893479  1.          2.        ]
 [ 0.59782594  0.89646041  0.08893479  1.          2.        ]
 [ 0.59782594  0.89646059  0.0889348   1.          2.        ]
 [ 0.59782594  0.89646065  0.08893481  1.          2.        ]
 [ 0.59782594  0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]]

STEP 4:
[[ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]
 [ 0.597826    0.89646071  0.08893482  1.          2.        ]]

