{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(35),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7cfba790>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7cfbad90>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd1fd1b790>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd7cfba190>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbd938b5cd0>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd9316ce90>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 0.001,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0.,  0.,  0., -2.,  0.])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 1000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 1000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [1000],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd93131d50>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 10,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd9316ce90>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 0.001,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0.,  0.,  0., -2.,  0.])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 1000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 1000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [1000],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd93131d50>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 10,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [1000],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 1000.0,
 'plan_f': <function <lambda> at 0x7fbd92c09f50>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 1000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[ 0.          0.          0.         -2.          0.        ]
 [-0.14803091 -0.02842637 -0.03732153 -2.          0.        ]
 [-0.15914471 -0.0307304  -0.03673055 -2.          0.        ]
 [-0.20596066 -0.04042404 -0.0332302  -2.          0.        ]
 [-0.25768462 -0.05113463 -0.02932293 -2.          0.        ]
 [-0.30250311 -0.0604151  -0.0259355  -2.          0.        ]
 [-0.34683338 -0.06959448 -0.02258634 -2.          0.        ]
 [-0.39014035 -0.07856196 -0.01931319 -2.          0.        ]
 [-0.43198133 -0.08722588 -0.01614982 -2.          0.        ]
 [-0.47284323 -0.09566762 -0.01128917 -2.          0.        ]
 [-0.51277983 -0.10389954 -0.00483683 -2.          0.        ]
 [-0.55117011 -0.11180416  0.0021497  -2.          0.        ]
 [-0.58756077 -0.11929361  0.00908411 -2.          0.        ]
 [-0.6218738  -0.12635441  0.01572124 -2.          0.        ]
 [-0.65416658 -0.13299923  0.02199094 -2.          0.        ]
 [-0.68453693 -0.13924846  0.02789    -2.          0.        ]
 [-0.71309614 -0.145125    0.03343571 -2.          0.        ]
 [-0.73995256 -0.1506512   0.03864938 -2.          0.        ]
 [-0.76520818 -0.15584801  0.04355161 -2.          0.        ]
 [-0.78895885 -0.16073518  0.04816145 -2.          0.        ]]

STEP 1:
[[-0.78895885 -0.16073518  0.04816145 -2.          0.        ]
 [-0.82096821 -0.16732952  0.05365518 -2.          0.        ]
 [-0.84412205 -0.17209436  0.05810501 -2.          0.        ]
 [-0.8638407  -0.17614791  0.06229194 -2.          0.        ]
 [-0.88159293 -0.17979766  0.06602202 -2.          0.        ]
 [-0.89855814 -0.18328768  0.06939279 -2.          0.        ]
 [-0.91440618 -0.18654841  0.07249884 -2.          0.        ]
 [-0.92926502 -0.18960577  0.07539319 -2.          0.        ]
 [-0.94324458 -0.19248231  0.07810733 -2.          0.        ]
 [-0.95638859 -0.19518697  0.0806581  -2.          0.        ]
 [-0.96874875 -0.19773029  0.08305676 -2.          0.        ]
 [-0.98037297 -0.20012221  0.08531266 -2.          0.        ]
 [-0.9913047  -0.20237158  0.0874343  -2.          0.        ]
 [-1.00158513 -0.20448698  0.08942958 -2.          0.        ]
 [-1.01125312 -0.20647636  0.09130601 -2.          0.        ]
 [-1.02034521 -0.20834723  0.09307066 -2.          0.        ]
 [-1.0288955  -0.21010664  0.09473018 -2.          0.        ]
 [-1.03693652 -0.21176118  0.09629082 -2.          0.        ]
 [-1.04449856 -0.21331719  0.09775851 -2.          0.        ]
 [-1.05160999 -0.21478054  0.09913874 -2.          0.        ]]

STEP 2:
[[-1.05160999 -0.21478054  0.09913874 -2.          0.        ]
 [-1.06119418 -0.21675502  0.10078368 -2.          0.        ]
 [-1.06812704 -0.2181817   0.10211606 -2.          0.        ]
 [-1.07403123 -0.21939541  0.10336972 -2.          0.        ]
 [-1.07934654 -0.22048828  0.10448659 -2.          0.        ]
 [-1.08442605 -0.22153325  0.10549588 -2.          0.        ]
 [-1.08917141 -0.22250952  0.10642584 -2.          0.        ]
 [-1.09362054 -0.22342499  0.10729247 -2.          0.        ]
 [-1.09780622 -0.22428627  0.10810516 -2.          0.        ]
 [-1.10174179 -0.22509611  0.10886893 -2.          0.        ]
 [-1.10544264 -0.22585763  0.10958714 -2.          0.        ]
 [-1.1089232  -0.22657382  0.11026261 -2.          0.        ]
 [-1.11219645 -0.22724731  0.11089786 -2.          0.        ]
 [-1.11527455 -0.2278807   0.11149528 -2.          0.        ]
 [-1.11816931 -0.22847635  0.11205707 -2.          0.        ]
 [-1.12089169 -0.22903652  0.11258548 -2.          0.        ]
 [-1.12345171 -0.22956334  0.11308239 -2.          0.        ]
 [-1.12585938 -0.23005876  0.11354966 -2.          0.        ]
 [-1.12812364 -0.23052464  0.11398912 -2.          0.        ]
 [-1.13025284 -0.2309628   0.11440239 -2.          0.        ]]

STEP 3:
[[-1.13025284 -0.2309628   0.11440239 -2.          0.        ]
 [-1.1331228  -0.23155399  0.1148949  -2.          0.        ]
 [-1.13519835 -0.23198116  0.11529384 -2.          0.        ]
 [-1.13696611 -0.23234461  0.11566921 -2.          0.        ]
 [-1.13855767 -0.23267175  0.11600363 -2.          0.        ]
 [-1.14007854 -0.23298466  0.11630581 -2.          0.        ]
 [-1.14149952 -0.23327699  0.11658426 -2.          0.        ]
 [-1.14283156 -0.2335511   0.11684377 -2.          0.        ]
 [-1.14408481 -0.23380899  0.1170871  -2.          0.        ]
 [-1.14526331 -0.2340515   0.11731579 -2.          0.        ]
 [-1.14637136 -0.23427948  0.11753082 -2.          0.        ]
 [-1.14741349 -0.23449394  0.11773307 -2.          0.        ]
 [-1.14839375 -0.23469558  0.11792328 -2.          0.        ]
 [-1.14931536 -0.23488526  0.11810217 -2.          0.        ]
 [-1.15018225 -0.23506363  0.11827037 -2.          0.        ]
 [-1.15099752 -0.23523135  0.1184286  -2.          0.        ]
 [-1.15176404 -0.23538908  0.1185774  -2.          0.        ]
 [-1.15248489 -0.23553742  0.11871734 -2.          0.        ]
 [-1.15316284 -0.23567694  0.11884891 -2.          0.        ]
 [-1.15380037 -0.2358081   0.11897267 -2.          0.        ]]

STEP 4:
[[-1.15380037 -0.2358081   0.11897267 -2.          0.        ]
 [-1.15465975 -0.23598513  0.11912016 -2.          0.        ]
 [-1.15528119 -0.23611304  0.11923959 -2.          0.        ]
 [-1.15581036 -0.23622189  0.11935202 -2.          0.        ]
 [-1.15628695 -0.23631983  0.11945214 -2.          0.        ]
 [-1.15674233 -0.23641352  0.11954258 -2.          0.        ]
 [-1.15716779 -0.23650102  0.11962595 -2.          0.        ]
 [-1.15756679 -0.2365831   0.11970363 -2.          0.        ]
 [-1.15794194 -0.23666036  0.11977651 -2.          0.        ]
 [-1.1582948  -0.23673292  0.11984501 -2.          0.        ]
 [-1.15862668 -0.23680124  0.11990938 -2.          0.        ]
 [-1.15893865 -0.23686543  0.11996994 -2.          0.        ]
 [-1.15923202 -0.2369258   0.12002689 -2.          0.        ]
 [-1.15950787 -0.23698257  0.12008045 -2.          0.        ]
 [-1.15976739 -0.23703592  0.1201308  -2.          0.        ]
 [-1.16001153 -0.23708615  0.12017814 -2.          0.        ]
 [-1.16024089 -0.2371334   0.1202227  -2.          0.        ]
 [-1.16045678 -0.2371778   0.1202646  -2.          0.        ]
 [-1.16065991 -0.23721959  0.12030401 -2.          0.        ]
 [-1.16085076 -0.23725885  0.12034107 -2.          0.        ]]

