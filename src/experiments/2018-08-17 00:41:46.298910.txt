{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(11),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd1f626090>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd1f626110>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd7d9b3fd0>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd24383b10>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbd7cbd7590>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0.,  1., -1.,  0.,  0.,  0.,  0.,  0.,  1., -1.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd9d04b750>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 0.001,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0.,  0.,  0.,  1., -1.])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 1000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 5000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [20],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd1f626b90>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 10,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd9d04b750>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 0.001,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0.,  0.,  0.,  1., -1.])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 1000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 5000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [20],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd1f626b90>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 10,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [20],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 1000.0,
 'plan_f': <function <lambda> at 0x7fbd7d9e0b18>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 5000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[ 0.          0.          0.          1.         -1.        ]
 [ 0.0752628  -0.10876676 -0.04590772  1.         -1.        ]
 [ 0.07810168 -0.11272165 -0.04534552  1.         -1.        ]
 [ 0.10378867 -0.14850655 -0.04025722  1.         -1.        ]
 [ 0.13519831 -0.19226368 -0.03402871  1.         -1.        ]
 [ 0.15969667 -0.22639263 -0.02917074  1.         -1.        ]
 [ 0.18395841 -0.26019192 -0.02435959  1.         -1.        ]
 [ 0.20783256 -0.29345128 -0.01962527  1.         -1.        ]
 [ 0.23042028 -0.32491851 -0.01514608  1.         -1.        ]
 [ 0.25208962 -0.35510629 -0.010849    1.         -1.        ]
 [ 0.27291605 -0.38411984 -0.00671907  1.         -1.        ]
 [ 0.29292709 -0.41199741 -0.00109101  1.         -1.        ]
 [ 0.31215084 -0.43877828  0.00529675  1.         -1.        ]
 [ 0.33028275 -0.46403804  0.01164391  1.         -1.        ]
 [ 0.34719497 -0.48759869  0.01764069  1.         -1.        ]
 [ 0.36295366 -0.50955236  0.02322971  1.         -1.        ]
 [ 0.37763643 -0.530007    0.02843009  1.         -1.        ]
 [ 0.39131469 -0.54906255  0.03327153  1.         -1.        ]
 [ 0.40405947 -0.56681734  0.03778132  1.         -1.        ]
 [ 0.4159351  -0.58336139  0.0419833   1.         -1.        ]]

STEP 1:
[[ 0.4159351  -0.58336139  0.0419833   1.         -1.        ]
 [ 0.43218344 -0.60599709  0.04721467  1.         -1.        ]
 [ 0.44362515 -0.6219368   0.05127461  1.         -1.        ]
 [ 0.45322996 -0.63531733  0.05497227  1.         -1.        ]
 [ 0.46154296 -0.64689827  0.0581166   1.         -1.        ]
 [ 0.46956569 -0.65807474  0.06096061  1.         -1.        ]
 [ 0.47699708 -0.66842759  0.06358925  1.         -1.        ]
 [ 0.48388153 -0.67801833  0.06602827  1.         -1.        ]
 [ 0.4903143  -0.68698001  0.06830209  1.         -1.        ]
 [ 0.49630851 -0.69533062  0.07042229  1.         -1.        ]
 [ 0.50189161 -0.70310843  0.07239798  1.         -1.        ]
 [ 0.5070948  -0.71035707  0.07423902  1.         -1.        ]
 [ 0.51194316 -0.71711147  0.07595456  1.         -1.        ]
 [ 0.51646072 -0.72340488  0.07755306  1.         -1.        ]
 [ 0.52067029 -0.72926927  0.07904255  1.         -1.        ]
 [ 0.52459264 -0.7347337   0.08043045  1.         -1.        ]
 [ 0.52824759 -0.73982537  0.08172369  1.         -1.        ]
 [ 0.53165323 -0.74456966  0.08292873  1.         -1.        ]
 [ 0.53482652 -0.74899054  0.08405156  1.         -1.        ]
 [ 0.53778344 -0.75310981  0.08509785  1.         -1.        ]]

STEP 2:
[[ 0.53778344 -0.75310981  0.08509785  1.         -1.        ]
 [ 0.54182923 -0.75874603  0.08640043  1.         -1.        ]
 [ 0.54467803 -0.76271486  0.08741134  1.         -1.        ]
 [ 0.54706967 -0.76604652  0.08833201  1.         -1.        ]
 [ 0.5491395  -0.76893008  0.08911493  1.         -1.        ]
 [ 0.55113709 -0.7717129   0.08982307  1.         -1.        ]
 [ 0.55298746 -0.77429068  0.09047759  1.         -1.        ]
 [ 0.55470169 -0.7766788   0.09108488  1.         -1.        ]
 [ 0.55630332 -0.77891028  0.09165105  1.         -1.        ]
 [ 0.55779588 -0.78098941  0.09217899  1.         -1.        ]
 [ 0.55918598 -0.78292596  0.0926709   1.         -1.        ]
 [ 0.56048155 -0.78473079  0.09312932  1.         -1.        ]
 [ 0.56168878 -0.7864126   0.09355646  1.         -1.        ]
 [ 0.56281358 -0.7879796   0.09395446  1.         -1.        ]
 [ 0.56386173 -0.78943992  0.09432533  1.         -1.        ]
 [ 0.56483847 -0.79080033  0.09467092  1.         -1.        ]
 [ 0.56574839 -0.79206812  0.09499292  1.         -1.        ]
 [ 0.56659645 -0.79324949  0.09529296  1.         -1.        ]
 [ 0.56738657 -0.79435027  0.09557255  1.         -1.        ]
 [ 0.5681228  -0.79537606  0.09583306  1.         -1.        ]]

STEP 3:
[[ 0.5681228  -0.79537606  0.09583306  1.         -1.        ]
 [ 0.56913018 -0.79677939  0.09615742  1.         -1.        ]
 [ 0.56983954 -0.79776764  0.09640913  1.         -1.        ]
 [ 0.57043499 -0.79859722  0.09663838  1.         -1.        ]
 [ 0.57095045 -0.79931521  0.09683332  1.         -1.        ]
 [ 0.57144785 -0.80000806  0.09700964  1.         -1.        ]
 [ 0.57190847 -0.80064988  0.0971726   1.         -1.        ]
 [ 0.5723353  -0.8012445   0.09732381  1.         -1.        ]
 [ 0.57273418 -0.80180013  0.09746477  1.         -1.        ]
 [ 0.57310575 -0.80231786  0.09759623  1.         -1.        ]
 [ 0.57345188 -0.80279994  0.09771872  1.         -1.        ]
 [ 0.57377446 -0.80324948  0.09783287  1.         -1.        ]
 [ 0.57407504 -0.80366814  0.09793922  1.         -1.        ]
 [ 0.57435513 -0.80405819  0.0980383   1.         -1.        ]
 [ 0.57461607 -0.8044219   0.09813061  1.         -1.        ]
 [ 0.57485932 -0.80476081  0.09821668  1.         -1.        ]
 [ 0.57508594 -0.80507636  0.09829687  1.         -1.        ]
 [ 0.575297   -0.80537057  0.09837158  1.         -1.        ]
 [ 0.57549381 -0.80564463  0.0984412   1.         -1.        ]
 [ 0.5756771  -0.80589998  0.09850606  1.         -1.        ]]

STEP 4:
[[ 0.5756771  -0.80589998  0.09850606  1.         -1.        ]
 [ 0.57592797 -0.80624938  0.09858681  1.         -1.        ]
 [ 0.57610452 -0.80649555  0.0986495   1.         -1.        ]
 [ 0.57625276 -0.80670202  0.09870659  1.         -1.        ]
 [ 0.57638109 -0.80688071  0.09875509  1.         -1.        ]
 [ 0.57650501 -0.80705333  0.09879901  1.         -1.        ]
 [ 0.57661968 -0.80721319  0.09883958  1.         -1.        ]
 [ 0.5767259  -0.80736113  0.09887725  1.         -1.        ]
 [ 0.5768252  -0.80749941  0.09891233  1.         -1.        ]
 [ 0.57691771 -0.80762839  0.09894507  1.         -1.        ]
 [ 0.5770039  -0.80774844  0.09897557  1.         -1.        ]
 [ 0.57708424 -0.80786026  0.09900397  1.         -1.        ]
 [ 0.57715899 -0.80796456  0.09903046  1.         -1.        ]
 [ 0.57722878 -0.80806172  0.09905514  1.         -1.        ]
 [ 0.57729375 -0.8081522   0.09907812  1.         -1.        ]
 [ 0.57735425 -0.8082366   0.09909953  1.         -1.        ]
 [ 0.5774107  -0.80831516  0.09911951  1.         -1.        ]
 [ 0.57746321 -0.80838823  0.0991381   1.         -1.        ]
 [ 0.57751226 -0.80845654  0.09915541  1.         -1.        ]
 [ 0.57755792 -0.80852008  0.09917156  1.         -1.        ]]

