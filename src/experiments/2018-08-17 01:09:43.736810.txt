{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(16),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd9d050750>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd9d050350>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd9329f450>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd9d050d90>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbd7d905fd0>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0., -3., -1.,  0.,  0.,  0.,  0.,  0., -3., -1.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd9329fe90>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 1.0,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0.,  0.,  0., -3., -1.])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 10000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 5000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [20],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd9d050390>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 10,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd9329fe90>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 1.0,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0.,  0.,  0., -3., -1.])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 10000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 5000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [20],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd9d050390>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 10,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [20],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 10000.0,
 'plan_f': <function <lambda> at 0x7fbd2437d668>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 5000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00  -3.00000000e+00
   -1.00000000e+00]
 [ -1.94631249e-01  -8.27769190e-02  -1.35305757e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -3.07214588e-01  -1.35285839e-01  -7.59395724e-03  -3.00000000e+00
   -1.00000000e+00]
 [ -4.12006557e-01  -1.84156269e-01  -2.06812378e-03  -3.00000000e+00
   -1.00000000e+00]
 [ -5.17785311e-01  -2.33484715e-01   3.50981113e-03  -3.00000000e+00
   -1.00000000e+00]
 [ -6.15327775e-01  -2.78973967e-01   8.65340699e-03  -3.00000000e+00
   -1.00000000e+00]
 [ -7.06563056e-01  -3.21521610e-01   1.34644145e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -7.92426288e-01  -3.61563921e-01   1.79921463e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -8.72976065e-01  -3.99128437e-01   2.22396925e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -9.48552430e-01  -4.34373558e-01   2.62249745e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -1.01948476e+00  -4.67452824e-01   2.99653597e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -1.08605194e+00  -4.98496532e-01   3.34755778e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -1.14852178e+00  -5.27629435e-01   3.67697366e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -1.20714748e+00  -5.54969549e-01   3.98611799e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -1.26216567e+00  -5.80627263e-01   4.27623950e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -1.31379783e+00  -6.04705870e-01   4.54850569e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -1.36225247e+00  -6.27302885e-01   4.80401590e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -1.40772557e+00  -6.48509204e-01   5.04380427e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -1.45039999e+00  -6.68410599e-01   5.26883341e-02  -3.00000000e+00
   -1.00000000e+00]
 [ -1.49044836e+00  -6.87087059e-01   5.48001714e-02  -3.00000000e+00
   -1.00000000e+00]]

STEP 1:
[[-1.49044836 -0.68708706  0.05480017 -3.         -1.        ]
 [-1.5462817  -0.71312404  0.05774439 -3.         -1.        ]
 [-1.58457422 -0.73098218  0.05976361 -3.         -1.        ]
 [-1.61701572 -0.74611193  0.06147433 -3.         -1.        ]
 [-1.64624798 -0.75974447  0.06301578 -3.         -1.        ]
 [-1.67431784 -0.77283478  0.06449594 -3.         -1.        ]
 [-1.70062327 -0.78510231  0.0658831  -3.         -1.        ]
 [-1.7252568  -0.79659027  0.06718206 -3.         -1.        ]
 [-1.74839115 -0.80737901  0.06840197 -3.         -1.        ]
 [-1.7701031  -0.81750429  0.06954689 -3.         -1.        ]
 [-1.79047668 -0.82700557  0.07062124 -3.         -1.        ]
 [-1.8095969  -0.8359223   0.07162947 -3.         -1.        ]
 [-1.82754087 -0.84429032  0.0725757  -3.         -1.        ]
 [-1.84438026 -0.85214341  0.07346366 -3.         -1.        ]
 [-1.8601836  -0.85951334  0.07429698 -3.         -1.        ]
 [-1.87501383 -0.86642957  0.07507905 -3.         -1.        ]
 [-1.88893187 -0.87292022  0.07581297 -3.         -1.        ]
 [-1.90199327 -0.87901145  0.07650172 -3.         -1.        ]
 [-1.91425109 -0.88472778  0.07714807 -3.         -1.        ]
 [-1.92575431 -0.89009225  0.07775467 -3.         -1.        ]]

STEP 2:
[[-1.92575431 -0.89009225  0.07775467 -3.         -1.        ]
 [-1.94179165 -0.89757109  0.07860037 -3.         -1.        ]
 [-1.95279074 -0.90270054  0.07918035 -3.         -1.        ]
 [-1.96210909 -0.90704644  0.07967173 -3.         -1.        ]
 [-1.9705056  -0.91096216  0.08011451 -3.         -1.        ]
 [-1.9785682  -0.91472214  0.08053964 -3.         -1.        ]
 [-1.98612416 -0.91824591  0.08093809 -3.         -1.        ]
 [-1.99319959 -0.92154545  0.08131118 -3.         -1.        ]
 [-1.99984455 -0.92464447  0.08166158 -3.         -1.        ]
 [-2.0060811  -0.92755276  0.08199045 -3.         -1.        ]
 [-2.01193309 -0.93028194  0.08229906 -3.         -1.        ]
 [-2.01742506 -0.93284315  0.08258866 -3.         -1.        ]
 [-2.02257895 -0.93524665  0.08286043 -3.         -1.        ]
 [-2.02741623 -0.93750232  0.08311548 -3.         -1.        ]
 [-2.03195548 -0.93961906  0.08335484 -3.         -1.        ]
 [-2.03621531 -0.94160593  0.08357948 -3.         -1.        ]
 [-2.04021311 -0.94347018  0.08379029 -3.         -1.        ]
 [-2.0439651  -0.94521999  0.08398814 -3.         -1.        ]
 [-2.04748583 -0.94686192  0.08417379 -3.         -1.        ]
 [-2.05078983 -0.94840276  0.08434802 -3.         -1.        ]]

STEP 3:
[[-2.05078983 -0.94840276  0.08434802 -3.         -1.        ]
 [-2.05539632 -0.95055091  0.08459095 -3.         -1.        ]
 [-2.0585556  -0.95202416  0.08475753 -3.         -1.        ]
 [-2.06123209 -0.95327246  0.08489867 -3.         -1.        ]
 [-2.06364393 -0.95439732  0.08502586 -3.         -1.        ]
 [-2.06595969 -0.95547724  0.08514798 -3.         -1.        ]
 [-2.06813025 -0.95648932  0.08526241 -3.         -1.        ]
 [-2.07016253 -0.95743716  0.08536958 -3.         -1.        ]
 [-2.07207131 -0.95832735  0.08547023 -3.         -1.        ]
 [-2.07386255 -0.95916277  0.0855647  -3.         -1.        ]
 [-2.07554317 -0.95994651  0.08565333 -3.         -1.        ]
 [-2.07712054 -0.96068209  0.08573651 -3.         -1.        ]
 [-2.07860112 -0.96137261  0.08581458 -3.         -1.        ]
 [-2.07999063 -0.96202058  0.08588786 -3.         -1.        ]
 [-2.0812943  -0.96262866  0.0859566  -3.         -1.        ]
 [-2.08251762 -0.96319914  0.08602111 -3.         -1.        ]
 [-2.08366609 -0.96373475  0.08608167 -3.         -1.        ]
 [-2.08474374 -0.96423727  0.0861385  -3.         -1.        ]
 [-2.08575511 -0.96470875  0.08619181 -3.         -1.        ]
 [-2.08670402 -0.96515131  0.08624186 -3.         -1.        ]]

STEP 4:
[[-2.08670402 -0.96515131  0.08624186 -3.         -1.        ]
 [-2.08802724 -0.96576834  0.08631162 -3.         -1.        ]
 [-2.0889349  -0.96619183  0.08635949 -3.         -1.        ]
 [-2.08970404 -0.96655041  0.08640003 -3.         -1.        ]
 [-2.09039664 -0.96687341  0.08643656 -3.         -1.        ]
 [-2.09106183 -0.96718353  0.08647164 -3.         -1.        ]
 [-2.0916853  -0.96747422  0.08650452 -3.         -1.        ]
 [-2.09226918 -0.96774656  0.0865353  -3.         -1.        ]
 [-2.09281731 -0.9680022   0.08656421 -3.         -1.        ]
 [-2.09333181 -0.96824211  0.08659133 -3.         -1.        ]
 [-2.09381485 -0.96846741  0.08661681 -3.         -1.        ]
 [-2.09426808 -0.96867871  0.08664072 -3.         -1.        ]
 [-2.09469342 -0.96887714  0.08666314 -3.         -1.        ]
 [-2.09509254 -0.96906334  0.08668418 -3.         -1.        ]
 [-2.09546709 -0.96923792  0.08670393 -3.         -1.        ]
 [-2.09581852 -0.9694019   0.08672246 -3.         -1.        ]
 [-2.09614825 -0.96955556  0.08673985 -3.         -1.        ]
 [-2.09645796 -0.96970004  0.08675618 -3.         -1.        ]
 [-2.09674859 -0.96983552  0.0867715  -3.         -1.        ]
 [-2.09702134 -0.96996272  0.08678588 -3.         -1.        ]]

