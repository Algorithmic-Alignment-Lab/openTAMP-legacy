{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(25),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7d889d50>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd7d020cd0>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd240a2390>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd7d4adcd0>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbd7db41910>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0., -3.,  1.,  0.,  0.,  0.,  0.,  0., -3.,  1.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd7d30fe10>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 0.001,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0.,  0.,  0., -3.,  1.])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 1000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 5000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [100],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd932353d0>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 0.01,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd7d30fe10>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 0.001,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0.,  0.,  0., -3.,  1.])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 1000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 5000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [100],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd932353d0>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 0.01,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [100],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 1000.0,
 'plan_f': <function <lambda> at 0x7fbd97acade8>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 5000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00  -3.00000000e+00
    1.00000000e+00]
 [ -1.46528929e-01   2.84519773e-02  -1.57302134e-02  -3.00000000e+00
    1.00000000e+00]
 [ -1.46528944e-01   2.84519754e-02  -1.57302544e-02  -3.00000000e+00
    1.00000000e+00]
 [ -1.51270047e-01   2.94004958e-02  -1.52650271e-02  -3.00000000e+00
    1.00000000e+00]
 [ -1.78803384e-01   3.49088907e-02  -1.25631671e-02  -3.00000000e+00
    1.00000000e+00]
 [ -1.97105676e-01   3.85705084e-02  -1.07671432e-02  -3.00000000e+00
    1.00000000e+00]
 [ -2.12810189e-01   4.17124107e-02  -9.22603812e-03  -3.00000000e+00
    1.00000000e+00]
 [ -2.28740022e-01   4.48993891e-02  -7.66281877e-03  -3.00000000e+00
    1.00000000e+00]
 [ -2.43288726e-01   4.78100590e-02  -6.23513479e-03  -3.00000000e+00
    1.00000000e+00]
 [ -2.56632566e-01   5.04796728e-02  -4.92568687e-03  -3.00000000e+00
    1.00000000e+00]
 [ -2.69064873e-01   5.29669300e-02  -3.70568596e-03  -3.00000000e+00
    1.00000000e+00]
 [ -2.80584157e-01   5.52715100e-02  -2.57528573e-03  -3.00000000e+00
    1.00000000e+00]
 [ -2.91247636e-01   5.74048832e-02  -1.52886286e-03  -3.00000000e+00
    1.00000000e+00]
 [ -3.01130652e-01   5.93821257e-02  -5.59024513e-04  -3.00000000e+00
    1.00000000e+00]
 [ -3.10288459e-01   6.12142645e-02   3.39644030e-04  -3.00000000e+00
    1.00000000e+00]
 [ -3.18773121e-01   6.29117340e-02   1.17225386e-03  -3.00000000e+00
    1.00000000e+00]
 [ -3.26634705e-01   6.44845441e-02   1.94372050e-03  -3.00000000e+00
    1.00000000e+00]
 [ -3.33918929e-01   6.59418553e-02   2.65853107e-03  -3.00000000e+00
    1.00000000e+00]
 [ -3.40668142e-01   6.72921240e-02   3.32084671e-03  -3.00000000e+00
    1.00000000e+00]
 [ -3.46921623e-01   6.85432255e-02   3.93450633e-03  -3.00000000e+00
    1.00000000e+00]]

STEP 1:
[[-0.34692162  0.06854323  0.00393451 -3.          1.        ]
 [-0.35530859  0.07022116  0.00475753 -3.          1.        ]
 [-0.36127087  0.07141396  0.00534261 -3.          1.        ]
 [-0.36618441  0.07239701  0.00582479 -3.          1.        ]
 [-0.37040353  0.07324111  0.00623882 -3.          1.        ]
 [-0.37449384  0.07405941  0.00664021 -3.          1.        ]
 [-0.37828001  0.07481688  0.00701174 -3.          1.        ]
 [-0.38176337  0.0755138   0.00735358 -3.          1.        ]
 [-0.3849985   0.07616101  0.00767104 -3.          1.        ]
 [-0.3879973   0.07676098  0.00796532 -3.          1.        ]
 [-0.39077446  0.07731658  0.00823784 -3.          1.        ]
 [-0.39334792  0.07783142  0.00849037 -3.          1.        ]
 [-0.3957324   0.07830848  0.00872438 -3.          1.        ]
 [-0.39794177  0.07875049  0.00894118 -3.          1.        ]
 [-0.3999888   0.07916004  0.00914206 -3.          1.        ]
 [-0.40188557  0.0795395   0.00932819 -3.          1.        ]
 [-0.40364295  0.07989109  0.00950065 -3.          1.        ]
 [-0.40527129  0.08021687  0.00966044 -3.          1.        ]
 [-0.40678003  0.08051872  0.0098085  -3.          1.        ]
 [-0.408178    0.08079839  0.00994567 -3.          1.        ]]

STEP 2:
[[-0.408178    0.08079839  0.00994567 -3.          1.        ]
 [-0.4100529   0.08117349  0.01012966 -3.          1.        ]
 [-0.41138574  0.08144014  0.01026045 -3.          1.        ]
 [-0.41248414  0.0816599   0.01036825 -3.          1.        ]
 [-0.41342726  0.08184858  0.0104608  -3.          1.        ]
 [-0.41434163  0.08203152  0.01055053 -3.          1.        ]
 [-0.41518801  0.08220084  0.01063358 -3.          1.        ]
 [-0.41596675  0.08235663  0.01071    -3.          1.        ]
 [-0.4166899   0.08250132  0.01078096 -3.          1.        ]
 [-0.41736031  0.08263544  0.01084675 -3.          1.        ]
 [-0.41798109  0.08275964  0.01090767 -3.          1.        ]
 [-0.41855636  0.08287473  0.01096412 -3.          1.        ]
 [-0.41908944  0.08298137  0.01101643 -3.          1.        ]
 [-0.41958329  0.08308019  0.0110649  -3.          1.        ]
 [-0.42004094  0.08317173  0.0111098  -3.          1.        ]
 [-0.42046493  0.08325656  0.01115141 -3.          1.        ]
 [-0.42085779  0.08333516  0.01118996 -3.          1.        ]
 [-0.42122182  0.08340798  0.01122569 -3.          1.        ]
 [-0.42155913  0.08347546  0.01125878 -3.          1.        ]
 [-0.42187163  0.08353799  0.01128945 -3.          1.        ]]

STEP 3:
[[-0.42187163  0.08353799  0.01128945 -3.          1.        ]
 [-0.42229071  0.08362184  0.01133058 -3.          1.        ]
 [-0.42258871  0.08368145  0.01135982 -3.          1.        ]
 [-0.42283425  0.08373056  0.01138391 -3.          1.        ]
 [-0.4230451   0.08377275  0.0114046  -3.          1.        ]
 [-0.42324948  0.08381364  0.01142466 -3.          1.        ]
 [-0.4234387   0.0838515   0.01144323 -3.          1.        ]
 [-0.42361274  0.08388633  0.01146032 -3.          1.        ]
 [-0.42377436  0.08391867  0.01147618 -3.          1.        ]
 [-0.42392427  0.08394864  0.01149088 -3.          1.        ]
 [-0.424063    0.08397641  0.0115045  -3.          1.        ]
 [-0.42419165  0.08400214  0.01151712 -3.          1.        ]
 [-0.42431077  0.08402598  0.01152881 -3.          1.        ]
 [-0.42442119  0.08404808  0.01153965 -3.          1.        ]
 [-0.4245235   0.08406853  0.01154968 -3.          1.        ]
 [-0.42461821  0.0840875   0.01155898 -3.          1.        ]
 [-0.42470607  0.08410506  0.0115676  -3.          1.        ]
 [-0.42478749  0.08412135  0.01157559 -3.          1.        ]
 [-0.42486289  0.08413643  0.01158298 -3.          1.        ]
 [-0.42493275  0.08415042  0.01158984 -3.          1.        ]]

STEP 4:
[[-0.42493275  0.08415042  0.01158984 -3.          1.        ]
 [-0.42502645  0.08416916  0.01159904 -3.          1.        ]
 [-0.42509302  0.08418249  0.01160557 -3.          1.        ]
 [-0.42514789  0.08419345  0.01161096 -3.          1.        ]
 [-0.42519504  0.0842029   0.01161558 -3.          1.        ]
 [-0.42524073  0.08421203  0.01162007 -3.          1.        ]
 [-0.42528301  0.08422049  0.01162422 -3.          1.        ]
 [-0.42532197  0.08422827  0.01162804 -3.          1.        ]
 [-0.42535812  0.0842355   0.01163158 -3.          1.        ]
 [-0.42539161  0.08424221  0.01163488 -3.          1.        ]
 [-0.42542261  0.08424842  0.01163791 -3.          1.        ]
 [-0.4254514   0.08425416  0.01164073 -3.          1.        ]
 [-0.42547804  0.0842595   0.01164335 -3.          1.        ]
 [-0.42550272  0.08426443  0.01164578 -3.          1.        ]
 [-0.42552558  0.084269    0.01164802 -3.          1.        ]
 [-0.42554677  0.08427325  0.0116501  -3.          1.        ]
 [-0.42556641  0.08427718  0.01165202 -3.          1.        ]
 [-0.42558461  0.08428082  0.01165381 -3.          1.        ]
 [-0.42560145  0.08428419  0.01165547 -3.          1.        ]
 [-0.42561707  0.08428732  0.011657   -3.          1.        ]]

