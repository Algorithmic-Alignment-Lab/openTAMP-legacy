{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(36),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd97b38110>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbd97b380d0>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd97b2c410>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbd97b38790>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbd97bd1cd0>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0.,  2., -1.,  0.,  0.,  0.,  0.,  0.,  2., -1.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd1fd1bfd0>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 0.001,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0.,  0.,  0.,  2., -1.])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 10000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 1000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [1000],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd1f63c0d0>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 10,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd1fd1bfd0>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 0.001,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0.,  0.,  0.,  2., -1.])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 10000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 1000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [1000],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbd1f63c0d0>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 10,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [1000],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 10000.0,
 'plan_f': <function <lambda> at 0x7fbd74033c80>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 1000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   2.00000000e+00
   -1.00000000e+00]
 [  1.27068505e-01  -8.98548067e-02  -5.15645184e-02   2.00000000e+00
   -1.00000000e+00]
 [  1.27146617e-01  -8.99095833e-02  -5.15719056e-02   2.00000000e+00
   -1.00000000e+00]
 [  1.66082248e-01  -1.17187023e-01  -4.72057499e-02   2.00000000e+00
   -1.00000000e+00]
 [  2.14638799e-01  -1.51205733e-01  -4.16497961e-02   2.00000000e+00
   -1.00000000e+00]
 [  2.54003555e-01  -1.78785384e-01  -3.70770358e-02   2.00000000e+00
   -1.00000000e+00]
 [  2.93275326e-01  -2.06300125e-01  -3.24863829e-02   2.00000000e+00
   -1.00000000e+00]
 [  3.32301080e-01  -2.33642668e-01  -2.79099066e-02   2.00000000e+00
   -1.00000000e+00]
 [  3.69982004e-01  -2.60042846e-01  -2.34734919e-02   2.00000000e+00
   -1.00000000e+00]
 [  4.06678826e-01  -2.85753548e-01  -1.91389509e-02   2.00000000e+00
   -1.00000000e+00]
 [  4.42459494e-01  -3.10822487e-01  -1.49036199e-02   2.00000000e+00
   -1.00000000e+00]
 [  4.77288067e-01  -3.35224330e-01  -1.07724927e-02   2.00000000e+00
   -1.00000000e+00]
 [  5.11197329e-01  -3.58982205e-01  -6.72544539e-03   2.00000000e+00
   -1.00000000e+00]
 [  5.44255257e-01  -3.82146299e-01  -1.67796388e-03   2.00000000e+00
   -1.00000000e+00]
 [  5.76408625e-01  -4.04677987e-01   3.80701572e-03   2.00000000e+00
   -1.00000000e+00]
 [  6.07245803e-01  -4.26287651e-01   9.21842456e-03   2.00000000e+00
   -1.00000000e+00]
 [  6.36624217e-01  -4.46875274e-01   1.44070499e-02   2.00000000e+00
   -1.00000000e+00]
 [  6.64609551e-01  -4.66486454e-01   1.93527304e-02   2.00000000e+00
   -1.00000000e+00]
 [  6.91267192e-01  -4.85167474e-01   2.40634345e-02   2.00000000e+00
   -1.00000000e+00]
 [  7.16656923e-01  -5.02959669e-01   2.85499059e-02   2.00000000e+00
   -1.00000000e+00]]

STEP 1:
[[ 0.71665692 -0.50295967  0.02854991  2.         -1.        ]
 [ 0.75140673 -0.52731073  0.03441203  2.         -1.        ]
 [ 0.77721751 -0.54539812  0.03896933  2.         -1.        ]
 [ 0.79934877 -0.5609076   0.04306262  2.         -1.        ]
 [ 0.81911004 -0.57475603  0.04666403  2.         -1.        ]
 [ 0.83850974 -0.58835095  0.05008409  2.         -1.        ]
 [ 0.85694492 -0.6012696   0.05334099  2.         -1.        ]
 [ 0.87443584 -0.61352682  0.05643497  2.         -1.        ]
 [ 0.89111924 -0.62521821  0.05938287  2.         -1.        ]
 [ 0.90701091 -0.63635451  0.06219128  2.         -1.        ]
 [ 0.9221437  -0.64695919  0.06486589  2.         -1.        ]
 [ 0.93655789 -0.65706033  0.06741334  2.         -1.        ]
 [ 0.95028716 -0.66668129  0.06983972  2.         -1.        ]
 [ 0.96336359 -0.67584473  0.07215077  2.         -1.        ]
 [ 0.9758181  -0.68457276  0.07435194  2.         -1.        ]
 [ 0.98768067 -0.69288576  0.07644847  2.         -1.        ]
 [ 0.99897945 -0.70080352  0.07844533  2.         -1.        ]
 [ 1.00974083 -0.70834494  0.08034727  2.         -1.        ]
 [ 1.01999068 -0.71552759  0.08215877  2.         -1.        ]
 [ 1.02975333 -0.72236907  0.08388415  2.         -1.        ]]

STEP 2:
[[ 1.02975333 -0.72236907  0.08388415  2.         -1.        ]
 [ 1.04311466 -0.73173201  0.08613835  2.         -1.        ]
 [ 1.05303895 -0.73868656  0.08789067  2.         -1.        ]
 [ 1.06154847 -0.74465007  0.08946455  2.         -1.        ]
 [ 1.06914687 -0.74997479  0.09084933  2.         -1.        ]
 [ 1.07660604 -0.75520211  0.09216434  2.         -1.        ]
 [ 1.08369446 -0.76016945  0.09341662  2.         -1.        ]
 [ 1.09041977 -0.76488239  0.09460627  2.         -1.        ]
 [ 1.09683454 -0.76937771  0.09573977  2.         -1.        ]
 [ 1.10294509 -0.77365971  0.09681959  2.         -1.        ]
 [ 1.10876369 -0.7777372   0.09784801  2.         -1.        ]
 [ 1.11430597 -0.7816211   0.0988275   2.         -1.        ]
 [ 1.1195848  -0.78532034  0.09976046  2.         -1.        ]
 [ 1.12461257 -0.78884375  0.10064907  2.         -1.        ]
 [ 1.12940168 -0.79219955  0.1014954   2.         -1.        ]
 [ 1.13396239 -0.79539597  0.10230154  2.         -1.        ]
 [ 1.13830686 -0.79844028  0.10306931  2.         -1.        ]
 [ 1.14244461 -0.80133998  0.10380057  2.         -1.        ]
 [ 1.14638567 -0.80410177  0.10449709  2.         -1.        ]
 [ 1.15013933 -0.8067323   0.10516052  2.         -1.        ]]

STEP 3:
[[ 1.15013933 -0.8067323   0.10516052  2.         -1.        ]
 [ 1.15527701 -0.81033236  0.10602728  2.         -1.        ]
 [ 1.1590929  -0.8130064   0.10670105  2.         -1.        ]
 [ 1.16236472 -0.81529951  0.10730621  2.         -1.        ]
 [ 1.1652863  -0.81734675  0.10783865  2.         -1.        ]
 [ 1.16815448 -0.81935668  0.10834429  2.         -1.        ]
 [ 1.17088008 -0.82126665  0.10882579  2.         -1.        ]
 [ 1.17346573 -0.82307863  0.10928321  2.         -1.        ]
 [ 1.17593241 -0.82480717  0.10971901  2.         -1.        ]
 [ 1.17828178 -0.82645357  0.11013424  2.         -1.        ]
 [ 1.1805191  -0.82802141  0.11052965  2.         -1.        ]
 [ 1.18265009 -0.82951486  0.11090629  2.         -1.        ]
 [ 1.18467975 -0.83093721  0.11126499  2.         -1.        ]
 [ 1.18661308 -0.83229202  0.11160669  2.         -1.        ]
 [ 1.18845439 -0.83358222  0.1119321   2.         -1.        ]
 [ 1.1902082  -0.83481127  0.11224204  2.         -1.        ]
 [ 1.19187856 -0.83598179  0.11253726  2.         -1.        ]
 [ 1.19346952 -0.83709675  0.11281845  2.         -1.        ]
 [ 1.19498491 -0.83815867  0.11308628  2.         -1.        ]
 [ 1.1964283  -0.8391701   0.11334135  2.         -1.        ]]

STEP 4:
[[ 1.1964283  -0.8391701   0.11334135  2.         -1.        ]
 [ 1.19840384 -0.84055442  0.11367458  2.         -1.        ]
 [ 1.19987082 -0.84158254  0.11393368  2.         -1.        ]
 [ 1.20112872 -0.84246421  0.11416636  2.         -1.        ]
 [ 1.20225215 -0.84325153  0.11437106  2.         -1.        ]
 [ 1.20335484 -0.84402424  0.11456549  2.         -1.        ]
 [ 1.20440292 -0.84475839  0.11475062  2.         -1.        ]
 [ 1.20539713 -0.84545523  0.11492649  2.         -1.        ]
 [ 1.20634556 -0.84611982  0.11509407  2.         -1.        ]
 [ 1.20724869 -0.84675294  0.1152537   2.         -1.        ]
 [ 1.2081089  -0.84735566  0.11540575  2.         -1.        ]
 [ 1.20892859 -0.84792989  0.11555055  2.         -1.        ]
 [ 1.20970893 -0.84847689  0.11568849  2.         -1.        ]
 [ 1.21045232 -0.84899783  0.11581983  2.         -1.        ]
 [ 1.21116042 -0.84949398  0.115945    2.         -1.        ]
 [ 1.21183467 -0.84996659  0.11606419  2.         -1.        ]
 [ 1.21247697 -0.85041654  0.11617771  2.         -1.        ]
 [ 1.21308875 -0.85084528  0.11628583  2.         -1.        ]
 [ 1.21367121 -0.85125357  0.11638878  2.         -1.        ]
 [ 1.21422625 -0.85164237  0.11648683  2.         -1.        ]]

