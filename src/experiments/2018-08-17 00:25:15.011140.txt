{'agent': {'T': 1,
           'action_inds': {('pr2', 'gripper'): array([2]),
                           ('pr2', 'pose'): array([0, 1])},
           'conditions': 1,
           'dU': 3,
           'dX': 5,
           'env': RaveGetEnvironment(4),
           'get_hl_plan': <function hl_plan_for_state at 0x7fbda60d8050>,
           'get_plan': <function get_plan at 0x7fbda60d8140>,
           'hist_len': 3,
           'image_channels': 3,
           'image_height': 140,
           'image_width': 140,
           'model': None,
           'num_cans': 1,
           'obs_include': [1,
                           9,
                           6],
           'openrave_bodies': {'can0': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbe1c5938d0>,
                               'pr2': <core.util_classes.openrave_body.OpenRAVEBody object at 0x7fbe1c5933d0>},
           'plans': {('grasp', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbe1c56c650>,
                     ('putdown', 'can0'): <core.internal_repr.plan.Plan object at 0x7fbe1c593950>},
           'sensor_dims': {0: 3,
                           1: 5,
                           6: 9,
                           8: 2,
                           9: 4},
           'solver': <__main__.NAMOPolicySolver object at 0x7fbdaefd7490>,
           'state_include': [1],
           'state_inds': {('can0', 'pose'): array([3, 4]),
                          ('can0_end_target', 'value'): array([12, 13]),
                          ('can0_init_target', 'value'): array([10, 11]),
                          ('grasp0', 'value'): array([5, 6]),
                          ('middle_target', 'value'): array([14, 15]),
                          ('pdp_target0', 'gripper'): array([21]),
                          ('pdp_target0', 'value'): array([19, 20]),
                          ('pr2', 'gripper'): array([2]),
                          ('pr2', 'pose'): array([0, 1]),
                          ('robot_end_pose', 'gripper'): array([18]),
                          ('robot_end_pose', 'value'): array([16, 17]),
                          ('robot_init_pose', 'gripper'): array([9]),
                          ('robot_init_pose', 'value'): array([7, 8])},
           'stochastic_conditions': True,
           'symbolic_bound': 5,
           'target_dim': 4,
           'target_inds': {('can0_end_target', 'value'): array([0, 1]),
                           ('middle_target', 'value'): array([2, 3])},
           'targets': [{'can0_end_target': [0.0,
                                            6.0],
                        'middle_target': [0.0,
                                          0.0]}],
           'task_breaks': [],
           'task_durations': {'grasp': 20,
                              'putdown': 20},
           'task_encoding': {'grasp': array([ 1.,  0.]),
                             'putdown': array([ 0.,  1.])},
           'task_list': ['grasp',
                         'putdown'],
           'type': <class 'policy_hooks.namo.namo_agent.NAMOSortingAgent'>,
           'viewer': None,
           'x0': [array([ 0.,  0.,  0., -1.,  1.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  0.,
        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]},
 'algorithm': {'grasp': {'T': 20,
                         'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd7d5caf10>,
                         'conditions': 1,
                         'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                'wp_final_multiplier': 1.0}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                            {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                'wp': array([[ 1.,  1.,  1.]])}},
                                             'ramp_option': 1,
                                             'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                  'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                  'weights': [1.0,
                                              1.0]},
                         'fit_dynamics': False,
                         'init_traj_distr': {'T': 20,
                                             'dQ': 3,
                                             'dU': 3,
                                             'dX': 5,
                                             'dt': 1.0,
                                             'init_var': 0.001,
                                             'pos_gains': 0.01,
                                             'type': <function init_pd at 0x7fbda60ed320>,
                                             'x0': [array([ 0.,  0.,  0., -1.,  1.])]},
                         'iterations': 10,
                         'kl_step': 0.1,
                         'max_ent_traj': 0.0,
                         'max_step_mult': 3.0,
                         'min_step_mult': 0.5,
                         'opt_wt': 10000.0,
                         'policy_opt': {'batch_size': 3000,
                                        'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'distilled_network_params': {'dim_hidden': [300,
                                                                                    300],
                                                                     'image_channels': 3,
                                                                     'image_height': 140,
                                                                     'image_width': 140,
                                                                     'n_layers': 2,
                                                                     'num_filters': [5,
                                                                                     10],
                                                                     'obs_image_data': [],
                                                                     'obs_include': [1,
                                                                                     9,
                                                                                     6],
                                                                     'sensor_dims': {0: 3,
                                                                                     1: 5,
                                                                                     6: 9,
                                                                                     8: 2,
                                                                                     9: 4}},
                                        'gpu_fraction': 0.2,
                                        'image_channels': 3,
                                        'image_height': 140,
                                        'image_width': 140,
                                        'iterations': 1000,
                                        'lr': 0.001,
                                        'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                        'network_params': {'dim_hidden': [20],
                                                           'image_channels': 3,
                                                           'image_height': 140,
                                                           'image_width': 140,
                                                           'n_layers': 1,
                                                           'num_filters': [5,
                                                                           10],
                                                           'obs_image_data': [],
                                                           'obs_include': [1,
                                                                           9,
                                                                           6],
                                                           'sensor_dims': {0: 3,
                                                                           1: 5,
                                                                           6: 9,
                                                                           8: 2,
                                                                           9: 4}},
                                        'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbe1c593ad0>,
                                        'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                        'task_list': ['grasp',
                                                      'putdown'],
                                        'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                        'weight_decay': 0.1,
                                        'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                         'policy_prior': {'max_clusters': 20,
                                          'max_samples': 20,
                                          'min_samples_per_cluster': 40,
                                          'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                         'policy_sample_mode': 'add',
                         'policy_transfer_coeff': 0.005,
                         'sample_on_policy': True,
                         'sample_ts_prob': 0.2,
                         'stochastic_conditions': True,
                         'traj_opt': {'covariance_damping': 10,
                                      'kl_threshold': 0.001,
                                      'min_temperature': 0.01,
                                      'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                         'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>},
               'putdown': {'T': 20,
                           'agent': <policy_hooks.namo.namo_agent.NAMOSortingAgent object at 0x7fbd7d5caf10>,
                           'conditions': 1,
                           'cost': {'costs': [{'data_types': {1: {'target_state': array([[ 0.,  0.,  0.,  0.,  0.]]),
                                                                  'wp': array([ 1.,  1.,  1.,  1.,  1.]),
                                                                  'wp_final_multiplier': 1.0}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.state_traj_cost.StateTrajCost'>},
                                              {'data_types': {0: {'target_state': array([[ 0.,  0.,  0.]]),
                                                                  'wp': array([[ 1.,  1.,  1.]])}},
                                               'ramp_option': 1,
                                               'type': <class 'policy_hooks.action_traj_cost.ActionTrajCost'>}],
                                    'type': <class 'gps.algorithm.cost.cost_sum.CostSum'>,
                                    'weights': [1.0,
                                                1.0]},
                           'fit_dynamics': False,
                           'init_traj_distr': {'T': 20,
                                               'dQ': 3,
                                               'dU': 3,
                                               'dX': 5,
                                               'dt': 1.0,
                                               'init_var': 0.001,
                                               'pos_gains': 0.01,
                                               'type': <function init_pd at 0x7fbda60ed320>,
                                               'x0': [array([ 0.,  0.,  0., -1.,  1.])]},
                           'iterations': 10,
                           'kl_step': 0.1,
                           'max_ent_traj': 0.0,
                           'max_step_mult': 3.0,
                           'min_step_mult': 0.5,
                           'opt_wt': 10000.0,
                           'policy_opt': {'batch_size': 3000,
                                          'distilled_network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'distilled_network_params': {'dim_hidden': [300,
                                                                                      300],
                                                                       'image_channels': 3,
                                                                       'image_height': 140,
                                                                       'image_width': 140,
                                                                       'n_layers': 2,
                                                                       'num_filters': [5,
                                                                                       10],
                                                                       'obs_image_data': [],
                                                                       'obs_include': [1,
                                                                                       9,
                                                                                       6],
                                                                       'sensor_dims': {0: 3,
                                                                                       1: 5,
                                                                                       6: 9,
                                                                                       8: 2,
                                                                                       9: 4}},
                                          'gpu_fraction': 0.2,
                                          'image_channels': 3,
                                          'image_height': 140,
                                          'image_width': 140,
                                          'iterations': 1000,
                                          'lr': 0.001,
                                          'network_model': <function tf_network at 0x7fbdbfd499b0>,
                                          'network_params': {'dim_hidden': [20],
                                                             'image_channels': 3,
                                                             'image_height': 140,
                                                             'image_width': 140,
                                                             'n_layers': 1,
                                                             'num_filters': [5,
                                                                             10],
                                                             'obs_image_data': [],
                                                             'obs_include': [1,
                                                                             9,
                                                                             6],
                                                             'sensor_dims': {0: 3,
                                                                             1: 5,
                                                                             6: 9,
                                                                             8: 2,
                                                                             9: 4}},
                                          'prev': <policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf object at 0x7fbe1c593ad0>,
                                          'primitive_network_model': <function tf_classification_network at 0x7fbda60fdc08>,
                                          'task_list': ['grasp',
                                                        'putdown'],
                                          'type': <class 'policy_hooks.multi_head_policy_opt_tf.MultiHeadPolicyOptTf'>,
                                          'weight_decay': 0.1,
                                          'weights_file_prefix': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks//experimentspolicy'},
                           'policy_prior': {'max_clusters': 20,
                                            'max_samples': 20,
                                            'min_samples_per_cluster': 40,
                                            'type': <class 'policy_hooks.policy_prior_gmm.PolicyPriorGMM'>},
                           'policy_sample_mode': 'add',
                           'policy_transfer_coeff': 0.005,
                           'sample_on_policy': True,
                           'sample_ts_prob': 0.2,
                           'stochastic_conditions': True,
                           'traj_opt': {'covariance_damping': 10,
                                        'kl_threshold': 0.001,
                                        'min_temperature': 0.01,
                                        'type': <class 'policy_hooks.traj_opt_pi2.TrajOptPI2'>},
                           'type': <class 'policy_hooks.algorithm_pigps.AlgorithmPIGPS'>}},
 'batch_size': 3000,
 'common': {'conditions': 1,
            'data_files_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/data_files/',
            'experiment_dir': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/',
            'experiment_name': 'my_experiment_08-17-18_00-19',
            'log_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/log.txt',
            'target_filename': '/home/michaelmcdonald/dependencies/tampy/src/policy_hooks/experiments/target.npz'},
 'cost_f': <function cost_f at 0x7fbda60d8488>,
 'dQ': 3,
 'dim_hidden': [20],
 'goal_f': <function goal_f at 0x7fbda60d8500>,
 'gui_on': False,
 'hist_len': 3,
 'iterations': 10,
 'lr': 0.001,
 'max_tree_depth': 3,
 'mode': 'position',
 'n_layers': 1,
 'num_conds': 1,
 'num_distilled_samples': 0,
 'num_rollouts': 8,
 'num_samples': 15,
 'opt_wt': 10000.0,
 'plan_f': <function <lambda> at 0x7fbd1f73e668>,
 'policy_coeff': 1.0,
 'sample_on_policy': True,
 'stochastic_conditions': True,
 'take_optimal_sample': True,
 'target_f': <function get_next_target at 0x7fbda60d8398>,
 'task_durations': {'grasp': 20,
                    'putdown': 20},
 'task_list': ['grasp',
               'putdown'],
 'train_iterations': 1000,
 'verbose_policy_trials': 1,
 'verbose_trials': 1,
 'weight_decay': 0.1}


<class 'gps.algorithm.cost.cost_sum.CostSum'>

STEP 0:
[[ 0.          0.          0.         -1.          1.        ]
 [-0.10111648  0.06019108 -0.04908937 -1.          1.        ]
 [-0.11922839  0.07108885 -0.04551876 -1.          1.        ]
 [-0.1559608   0.09319039 -0.03827695 -1.          1.        ]
 [-0.19626997  0.11744404 -0.03032997 -1.          1.        ]
 [-0.22876506  0.13699603 -0.02392355 -1.          1.        ]
 [-0.25916001  0.15527914 -0.01626069 -1.          1.        ]
 [-0.28796068  0.17259309 -0.00573647 -1.          1.        ]
 [-0.31437087  0.1884661   0.00514063 -1.          1.        ]
 [-0.33817589  0.20277223  0.01531126 -1.          1.        ]
 [-0.35948962  0.21558094  0.024484   -1.          1.        ]
 [-0.37853786  0.22702822  0.03267998 -1.          1.        ]
 [-0.39555806  0.23725675  0.03999516 -1.          1.        ]
 [-0.41076806  0.24639735  0.04652804 -1.          1.        ]
 [-0.42436159  0.25456658  0.05236521 -1.          1.        ]
 [-0.43651098  0.26186794  0.05758192 -1.          1.        ]
 [-0.44736987  0.26839375  0.06224449 -1.          1.        ]
 [-0.45707536  0.2742264   0.06641182 -1.          1.        ]
 [-0.46574992  0.27943948  0.07013649 -1.          1.        ]
 [-0.47350302  0.28409886  0.07346556 -1.          1.        ]]

STEP 1:
[[-0.47350302  0.28409886  0.07346556 -1.          1.        ]
 [-0.48328966  0.28998125  0.0773581  -1.          1.        ]
 [-0.48996267  0.29399145  0.08022539 -1.          1.        ]
 [-0.49539265  0.29725415  0.08272366 -1.          1.        ]
 [-0.49990809  0.29996741  0.08478948 -1.          1.        ]
 [-0.50406301  0.30246434  0.08658545 -1.          1.        ]
 [-0.50775862  0.30468526  0.08817403 -1.          1.        ]
 [-0.51104403  0.30665967  0.08958645 -1.          1.        ]
 [-0.51398605  0.30842769  0.09084877 -1.          1.        ]
 [-0.51661587  0.31000814  0.09197754 -1.          1.        ]
 [-0.51896578  0.31142032  0.09298649 -1.          1.        ]
 [-0.52106619  0.31268263  0.09388839 -1.          1.        ]
 [-0.52294362  0.31381088  0.09469448 -1.          1.        ]
 [-0.52462161  0.31481925  0.09541497 -1.          1.        ]
 [-0.52612126  0.31572053  0.09605892 -1.          1.        ]
 [-0.52746171  0.31652609  0.09663448 -1.          1.        ]
 [-0.52865976  0.31724608  0.0971489  -1.          1.        ]
 [-0.52973056  0.3178896   0.09760867 -1.          1.        ]
 [-0.53068769  0.31846473  0.09801961 -1.          1.        ]
 [-0.53154302  0.31897879  0.0983869  -1.          1.        ]]

STEP 2:
[[-0.53154302  0.31897879  0.0983869  -1.          1.        ]
 [-0.53262269  0.31962779  0.09881638 -1.          1.        ]
 [-0.53335893  0.32007024  0.0991327  -1.          1.        ]
 [-0.53395808  0.32043013  0.09940831 -1.          1.        ]
 [-0.53445619  0.32072955  0.09963624 -1.          1.        ]
 [-0.53491461  0.32100502  0.0998344  -1.          1.        ]
 [-0.53532237  0.32125005  0.10000966 -1.          1.        ]
 [-0.53568482  0.32146791  0.10016549 -1.          1.        ]
 [-0.53600937  0.32166293  0.10030478 -1.          1.        ]
 [-0.53629953  0.32183728  0.10042931 -1.          1.        ]
 [-0.53655881  0.32199311  0.10054061 -1.          1.        ]
 [-0.53679049  0.32213241  0.10064012 -1.          1.        ]
 [-0.53699768  0.32225686  0.10072905 -1.          1.        ]
 [-0.53718281  0.32236812  0.10080852 -1.          1.        ]
 [-0.53734827  0.32246757  0.10087959 -1.          1.        ]
 [-0.53749615  0.32255641  0.1009431  -1.          1.        ]
 [-0.53762829  0.32263583  0.10099985 -1.          1.        ]
 [-0.53774643  0.32270685  0.10105057 -1.          1.        ]
 [-0.53785205  0.32277027  0.10109587 -1.          1.        ]
 [-0.5379464   0.32282701  0.1011364  -1.          1.        ]]

STEP 3:
[[-0.5379464   0.32282701  0.1011364  -1.          1.        ]
 [-0.53806555  0.32289866  0.1011838  -1.          1.        ]
 [-0.53814673  0.32294744  0.1012187  -1.          1.        ]
 [-0.5382129   0.32298714  0.1012491  -1.          1.        ]
 [-0.53826779  0.32302016  0.10127427 -1.          1.        ]
 [-0.53831834  0.32305056  0.10129611 -1.          1.        ]
 [-0.5383634   0.32307756  0.10131544 -1.          1.        ]
 [-0.53840333  0.32310161  0.10133263 -1.          1.        ]
 [-0.53843915  0.32312316  0.101348   -1.          1.        ]
 [-0.53847122  0.32314238  0.10136175 -1.          1.        ]
 [-0.53849971  0.32315958  0.10137405 -1.          1.        ]
 [-0.53852534  0.32317492  0.10138501 -1.          1.        ]
 [-0.53854817  0.32318866  0.10139482 -1.          1.        ]
 [-0.53856862  0.32320091  0.10140358 -1.          1.        ]
 [-0.53858685  0.32321191  0.10141142 -1.          1.        ]
 [-0.53860319  0.32322171  0.10141844 -1.          1.        ]
 [-0.53861773  0.32323048  0.10142471 -1.          1.        ]
 [-0.53863072  0.32323828  0.10143028 -1.          1.        ]
 [-0.53864241  0.32324526  0.10143529 -1.          1.        ]
 [-0.53865278  0.32325155  0.10143976 -1.          1.        ]]

STEP 4:
[[-0.53865278  0.32325155  0.10143976 -1.          1.        ]
 [-0.53866589  0.32325941  0.10144497 -1.          1.        ]
 [-0.53867483  0.32326481  0.1014488  -1.          1.        ]
 [-0.53868216  0.32326916  0.10145214 -1.          1.        ]
 [-0.53868818  0.32327279  0.10145491 -1.          1.        ]
 [-0.53869379  0.32327619  0.10145733 -1.          1.        ]
 [-0.53869879  0.3232792   0.10145947 -1.          1.        ]
 [-0.5387032   0.32328182  0.10146138 -1.          1.        ]
 [-0.53870714  0.32328421  0.10146308 -1.          1.        ]
 [-0.53871071  0.32328632  0.1014646  -1.          1.        ]
 [-0.53871381  0.32328826  0.10146596 -1.          1.        ]
 [-0.53871667  0.32328993  0.10146716 -1.          1.        ]
 [-0.53871924  0.32329145  0.10146827 -1.          1.        ]
 [-0.53872144  0.32329285  0.10146923 -1.          1.        ]
 [-0.53872347  0.32329404  0.1014701  -1.          1.        ]
 [-0.53872532  0.32329512  0.10147086 -1.          1.        ]
 [-0.53872693  0.32329604  0.10147154 -1.          1.        ]
 [-0.53872836  0.32329696  0.10147218 -1.          1.        ]
 [-0.53872967  0.32329774  0.10147275 -1.          1.        ]
 [-0.5387308   0.32329842  0.10147324 -1.          1.        ]]

